/data/cl/u/nsarkar/miniconda/envs/litgpt/lib/python3.11/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /data/cl/u/nsarkar/miniconda/envs/litgpt/bin/litgpt  ...
Using bfloat16 Automatic Mixed Precision (AMP)
wandb: Currently logged in as: nandan-sarkar (pcfg_pretrain). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.2
wandb: Run data is saved locally in ./wandb/run-20240707_152449-g2hjz72t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-microwave-130
wandb: ‚≠êÔ∏è View project at https://wandb.ai/pcfg_pretrain/pretrain-
wandb: üöÄ View run at https://wandb.ai/pcfg_pretrain/pretrain-/runs/g2hjz72t
[rank: 0] Seed set to 42
{'data': {'batch_size': 1,
          'max_seq_length': -1,
          'num_workers': 4,
          'seed': 42,
          'tokenizer': None,
          'train_data_path': PosixPath('/data/cl/u/nsarkar/generated_data/pcfg/50M_tokens'),
          'val_data_path': PosixPath('/data/cl/u/nsarkar/BabyLM_cleaned/val_set')},
 'devices': 1,
 'eval': {'final_validation': True,
          'initial_validation': True,
          'interval': 100,
          'max_iters': 100,
          'max_new_tokens': None},
 'initial_checkpoint_dir': None,
 'logger_name': 'wandb',
 'model_config': {'bias': True,
                  'block_size': 1024,
                  'gelu_approximate': 'none',
                  'head_size': 64,
                  'hf_config': {},
                  'intermediate_size': 2048,
                  'lm_head_bias': False,
                  'mlp_class_name': 'LLaMAMLP',
                  'n_embd': 512,
                  'n_expert': 0,
                  'n_expert_per_token': 0,
                  'n_head': 8,
                  'n_layer': 6,
                  'n_query_groups': 4,
                  'name': '',
                  'norm_class_name': 'RMSNorm',
                  'norm_eps': 1e-05,
                  'padded_vocab_size': 50304,
                  'padding_multiple': 512,
                  'parallel_residual': True,
                  'rope_base': 10000,
                  'rope_condense_ratio': 1,
                  'rotary_percentage': 1.0,
                  'scale_embeddings': False,
                  'shared_attention_norm': False,
                  'vocab_size': 50254},
 'model_name': 'custom-lm_75_1M_on_pcfg_50',
 'optimizer': "{'class_path': 'torch.optim.AdamW', 'init_args': {'lr': 0.001, "
              "'weight_decay': 0.01, 'betas': [0.9, 0.95]}}",
 'out_dir': PosixPath('out/pretrain/custom-lm_75_1M_on_pcfg_50'),
 'precision': None,
 'resume': False,
 'seed': 42,
 'tokenizer_dir': PosixPath('/data/cl/u/nsarkar/litgpt/checkpoints/openai-community/gpt2'),
 'train': {'epochs': None,
           'global_batch_size': 32,
           'log_interval': 10,
           'lr_warmup_fraction': None,
           'lr_warmup_steps': 875,
           'max_norm': 1.0,
           'max_seq_length': None,
           'max_steps': None,
           'max_tokens': 300000048,
           'micro_batch_size': 32,
           'min_lr': 4e-05,
           'save_interval': 1000,
           'tie_embeddings': False}}
Time to instantiate model: 0.22 seconds.
Total parameters: 75,147,776
Validating ...
Measured TFLOPs: 10.94
Epoch 1 | iter 10 step 10 | loss train: 10.469, val: 11.001 | iter time: 139.23 ms (step) remaining time: 3:26:05
Epoch 1 | iter 20 step 20 | loss train: 9.520, val: 11.001 | iter time: 138.52 ms (step) remaining time: 1:53:29
Epoch 1 | iter 30 step 30 | loss train: 8.956, val: 11.001 | iter time: 140.87 ms (step) remaining time: 1:22:36
Epoch 1 | iter 40 step 40 | loss train: 8.474, val: 11.001 | iter time: 140.20 ms (step) remaining time: 1:07:10
Epoch 1 | iter 50 step 50 | loss train: 8.054, val: 11.001 | iter time: 138.97 ms (step) remaining time: 0:57:54
Epoch 1 | iter 60 step 60 | loss train: 7.589, val: 11.001 | iter time: 140.25 ms (step) remaining time: 0:51:42
Epoch 1 | iter 70 step 70 | loss train: 7.166, val: 11.001 | iter time: 139.64 ms (step) remaining time: 0:47:17
Epoch 1 | iter 80 step 80 | loss train: 6.777, val: 11.001 | iter time: 139.81 ms (step) remaining time: 0:43:57
Epoch 1 | iter 90 step 90 | loss train: 6.409, val: 11.001 | iter time: 138.82 ms (step) remaining time: 0:41:21
Epoch 1 | iter 100 step 100 | loss train: 6.080, val: 11.001 | iter time: 140.20 ms (step) remaining time: 0:39:16
Validating ...
iter 100: val loss 6.6750, val time: 4291.25 ms
Epoch 1 | iter 110 step 110 | loss train: 5.854, val: 6.675 | iter time: 140.10 ms (step) remaining time: 0:43:26
Epoch 1 | iter 120 step 120 | loss train: 5.739, val: 6.675 | iter time: 139.64 ms (step) remaining time: 0:41:31
Epoch 1 | iter 130 step 130 | loss train: 5.610, val: 6.675 | iter time: 139.71 ms (step) remaining time: 0:39:54
Epoch 1 | iter 140 step 140 | loss train: 5.498, val: 6.675 | iter time: 138.99 ms (step) remaining time: 0:38:30
Epoch 1 | iter 150 step 150 | loss train: 5.436, val: 6.675 | iter time: 140.21 ms (step) remaining time: 0:37:17
Epoch 1 | iter 160 step 160 | loss train: 5.405, val: 6.675 | iter time: 140.22 ms (step) remaining time: 0:36:13
Epoch 1 | iter 170 step 170 | loss train: 5.345, val: 6.675 | iter time: 139.92 ms (step) remaining time: 0:35:17
Epoch 1 | iter 180 step 180 | loss train: 5.257, val: 6.675 | iter time: 140.29 ms (step) remaining time: 0:34:26
Epoch 1 | iter 190 step 190 | loss train: 5.266, val: 6.675 | iter time: 140.54 ms (step) remaining time: 0:33:41
Epoch 1 | iter 200 step 200 | loss train: 5.208, val: 6.675 | iter time: 139.71 ms (step) remaining time: 0:33:00
Validating ...
iter 200: val loss 5.9200, val time: 4285.72 ms
Epoch 1 | iter 210 step 210 | loss train: 5.225, val: 5.920 | iter time: 140.10 ms (step) remaining time: 0:35:26
Epoch 1 | iter 220 step 220 | loss train: 5.152, val: 5.920 | iter time: 141.17 ms (step) remaining time: 0:34:44
Epoch 1 | iter 230 step 230 | loss train: 5.112, val: 5.920 | iter time: 141.50 ms (step) remaining time: 0:34:06
Epoch 1 | iter 240 step 240 | loss train: 5.117, val: 5.920 | iter time: 140.99 ms (step) remaining time: 0:33:30
Epoch 1 | iter 250 step 250 | loss train: 5.121, val: 5.920 | iter time: 139.82 ms (step) remaining time: 0:32:57
Epoch 1 | iter 260 step 260 | loss train: 5.138, val: 5.920 | iter time: 141.07 ms (step) remaining time: 0:32:27
Epoch 1 | iter 270 step 270 | loss train: 5.061, val: 5.920 | iter time: 141.67 ms (step) remaining time: 0:31:59
Epoch 1 | iter 280 step 280 | loss train: 5.059, val: 5.920 | iter time: 140.32 ms (step) remaining time: 0:31:33
Epoch 1 | iter 290 step 290 | loss train: 5.088, val: 5.920 | iter time: 141.02 ms (step) remaining time: 0:31:09
Epoch 1 | iter 300 step 300 | loss train: 5.029, val: 5.920 | iter time: 140.80 ms (step) remaining time: 0:30:46
Validating ...
iter 300: val loss 5.7723, val time: 4321.83 ms
Epoch 1 | iter 310 step 310 | loss train: 5.042, val: 5.772 | iter time: 141.86 ms (step) remaining time: 0:32:27
Epoch 1 | iter 320 step 320 | loss train: 5.060, val: 5.772 | iter time: 141.00 ms (step) remaining time: 0:32:03
Epoch 1 | iter 330 step 330 | loss train: 5.035, val: 5.772 | iter time: 140.84 ms (step) remaining time: 0:31:40
Epoch 1 | iter 340 step 340 | loss train: 5.045, val: 5.772 | iter time: 142.75 ms (step) remaining time: 0:31:19
Epoch 1 | iter 350 step 350 | loss train: 5.017, val: 5.772 | iter time: 141.19 ms (step) remaining time: 0:30:58
Epoch 1 | iter 360 step 360 | loss train: 4.991, val: 5.772 | iter time: 140.76 ms (step) remaining time: 0:30:39
Epoch 1 | iter 370 step 370 | loss train: 4.981, val: 5.772 | iter time: 141.64 ms (step) remaining time: 0:30:21
Epoch 1 | iter 380 step 380 | loss train: 5.033, val: 5.772 | iter time: 140.91 ms (step) remaining time: 0:30:03
Epoch 1 | iter 390 step 390 | loss train: 5.047, val: 5.772 | iter time: 141.30 ms (step) remaining time: 0:29:46
Epoch 1 | iter 400 step 400 | loss train: 4.998, val: 5.772 | iter time: 140.61 ms (step) remaining time: 0:29:30
Validating ...
iter 400: val loss 5.7348, val time: 4296.57 ms
Epoch 1 | iter 410 step 410 | loss train: 4.974, val: 5.735 | iter time: 140.49 ms (step) remaining time: 0:30:47
Epoch 1 | iter 420 step 420 | loss train: 5.006, val: 5.735 | iter time: 140.82 ms (step) remaining time: 0:30:30
Epoch 1 | iter 430 step 430 | loss train: 4.987, val: 5.735 | iter time: 142.07 ms (step) remaining time: 0:30:14
Epoch 1 | iter 440 step 440 | loss train: 4.965, val: 5.735 | iter time: 140.99 ms (step) remaining time: 0:29:58
Epoch 1 | iter 450 step 450 | loss train: 4.973, val: 5.735 | iter time: 141.60 ms (step) remaining time: 0:29:44
Epoch 1 | iter 460 step 460 | loss train: 4.956, val: 5.735 | iter time: 142.21 ms (step) remaining time: 0:29:29
Epoch 1 | iter 470 step 470 | loss train: 4.983, val: 5.735 | iter time: 141.60 ms (step) remaining time: 0:29:16
Epoch 1 | iter 480 step 480 | loss train: 4.997, val: 5.735 | iter time: 140.74 ms (step) remaining time: 0:29:03
Epoch 1 | iter 490 step 490 | loss train: 5.066, val: 5.735 | iter time: 141.21 ms (step) remaining time: 0:28:50
Epoch 1 | iter 500 step 500 | loss train: 4.963, val: 5.735 | iter time: 140.80 ms (step) remaining time: 0:28:38
Validating ...
iter 500: val loss 5.7043, val time: 4334.74 ms
Epoch 1 | iter 510 step 510 | loss train: 4.972, val: 5.704 | iter time: 141.35 ms (step) remaining time: 0:29:39
Epoch 1 | iter 520 step 520 | loss train: 4.956, val: 5.704 | iter time: 143.08 ms (step) remaining time: 0:29:27
Epoch 1 | iter 530 step 530 | loss train: 4.957, val: 5.704 | iter time: 140.98 ms (step) remaining time: 0:29:14
Epoch 1 | iter 540 step 540 | loss train: 4.911, val: 5.704 | iter time: 141.24 ms (step) remaining time: 0:29:02
Epoch 1 | iter 550 step 550 | loss train: 4.948, val: 5.704 | iter time: 141.26 ms (step) remaining time: 0:28:51
Epoch 1 | iter 560 step 560 | loss train: 4.945, val: 5.704 | iter time: 142.84 ms (step) remaining time: 0:28:39
Epoch 1 | iter 570 step 570 | loss train: 4.977, val: 5.704 | iter time: 141.92 ms (step) remaining time: 0:28:28
Epoch 1 | iter 580 step 580 | loss train: 4.937, val: 5.704 | iter time: 141.54 ms (step) remaining time: 0:28:18
Epoch 1 | iter 590 step 590 | loss train: 4.934, val: 5.704 | iter time: 141.19 ms (step) remaining time: 0:28:07
Epoch 1 | iter 600 step 600 | loss train: 4.932, val: 5.704 | iter time: 141.49 ms (step) remaining time: 0:27:57
Validating ...
iter 600: val loss 5.6926, val time: 4341.95 ms
Epoch 1 | iter 610 step 610 | loss train: 4.947, val: 5.693 | iter time: 142.78 ms (step) remaining time: 0:28:49
Epoch 1 | iter 620 step 620 | loss train: 4.925, val: 5.693 | iter time: 142.49 ms (step) remaining time: 0:28:38
Epoch 1 | iter 630 step 630 | loss train: 4.971, val: 5.693 | iter time: 141.37 ms (step) remaining time: 0:28:28
Epoch 1 | iter 640 step 640 | loss train: 4.985, val: 5.693 | iter time: 141.92 ms (step) remaining time: 0:28:22
Epoch 1 | iter 650 step 650 | loss train: 4.911, val: 5.693 | iter time: 141.23 ms (step) remaining time: 0:28:12
Epoch 1 | iter 660 step 660 | loss train: 4.938, val: 5.693 | iter time: 141.55 ms (step) remaining time: 0:28:03
Epoch 1 | iter 670 step 670 | loss train: 4.924, val: 5.693 | iter time: 141.07 ms (step) remaining time: 0:27:53
Epoch 1 | iter 680 step 680 | loss train: 4.965, val: 5.693 | iter time: 141.30 ms (step) remaining time: 0:27:44
Epoch 1 | iter 690 step 690 | loss train: 4.878, val: 5.693 | iter time: 141.40 ms (step) remaining time: 0:27:36
Epoch 1 | iter 700 step 700 | loss train: 4.950, val: 5.693 | iter time: 142.14 ms (step) remaining time: 0:27:27
Validating ...
iter 700: val loss 5.6869, val time: 4313.87 ms
Epoch 1 | iter 710 step 710 | loss train: 4.939, val: 5.687 | iter time: 142.70 ms (step) remaining time: 0:28:10
Epoch 1 | iter 720 step 720 | loss train: 4.939, val: 5.687 | iter time: 142.51 ms (step) remaining time: 0:28:01
Epoch 1 | iter 730 step 730 | loss train: 4.936, val: 5.687 | iter time: 141.71 ms (step) remaining time: 0:27:52
Epoch 1 | iter 740 step 740 | loss train: 4.899, val: 5.687 | iter time: 141.47 ms (step) remaining time: 0:27:44
Epoch 1 | iter 750 step 750 | loss train: 4.925, val: 5.687 | iter time: 141.74 ms (step) remaining time: 0:27:36
Epoch 1 | iter 760 step 760 | loss train: 4.953, val: 5.687 | iter time: 140.56 ms (step) remaining time: 0:27:28
Epoch 1 | iter 770 step 770 | loss train: 4.928, val: 5.687 | iter time: 142.73 ms (step) remaining time: 0:27:20
Epoch 1 | iter 780 step 780 | loss train: 4.979, val: 5.687 | iter time: 141.78 ms (step) remaining time: 0:27:12
Epoch 1 | iter 790 step 790 | loss train: 4.932, val: 5.687 | iter time: 142.69 ms (step) remaining time: 0:27:05
Epoch 1 | iter 800 step 800 | loss train: 4.916, val: 5.687 | iter time: 142.89 ms (step) remaining time: 0:26:57
Validating ...
iter 800: val loss 5.6766, val time: 4312.30 ms
Epoch 1 | iter 810 step 810 | loss train: 4.943, val: 5.677 | iter time: 142.54 ms (step) remaining time: 0:27:34
Epoch 1 | iter 820 step 820 | loss train: 4.954, val: 5.677 | iter time: 141.45 ms (step) remaining time: 0:27:27
Epoch 1 | iter 830 step 830 | loss train: 4.923, val: 5.677 | iter time: 141.30 ms (step) remaining time: 0:27:19
Epoch 1 | iter 840 step 840 | loss train: 4.947, val: 5.677 | iter time: 141.87 ms (step) remaining time: 0:27:11
Epoch 1 | iter 850 step 850 | loss train: 4.921, val: 5.677 | iter time: 140.42 ms (step) remaining time: 0:27:04
Epoch 1 | iter 860 step 860 | loss train: 4.945, val: 5.677 | iter time: 140.66 ms (step) remaining time: 0:26:57
Epoch 1 | iter 870 step 870 | loss train: 4.906, val: 5.677 | iter time: 141.18 ms (step) remaining time: 0:26:50
Epoch 1 | iter 880 step 880 | loss train: 4.861, val: 5.677 | iter time: 142.19 ms (step) remaining time: 0:26:43
Epoch 1 | iter 890 step 890 | loss train: 4.918, val: 5.677 | iter time: 141.65 ms (step) remaining time: 0:26:36
Epoch 1 | iter 900 step 900 | loss train: 4.926, val: 5.677 | iter time: 141.68 ms (step) remaining time: 0:26:29
Validating ...
iter 900: val loss 5.6764, val time: 4319.90 ms
Epoch 1 | iter 910 step 910 | loss train: 4.893, val: 5.676 | iter time: 141.66 ms (step) remaining time: 0:27:02
Epoch 1 | iter 920 step 920 | loss train: 4.883, val: 5.676 | iter time: 140.07 ms (step) remaining time: 0:26:55
Epoch 1 | iter 930 step 930 | loss train: 4.906, val: 5.676 | iter time: 142.13 ms (step) remaining time: 0:26:48
Epoch 1 | iter 940 step 940 | loss train: 4.931, val: 5.676 | iter time: 140.89 ms (step) remaining time: 0:26:41
Epoch 1 | iter 950 step 950 | loss train: 4.923, val: 5.676 | iter time: 143.18 ms (step) remaining time: 0:26:35
Epoch 1 | iter 960 step 960 | loss train: 4.966, val: 5.676 | iter time: 141.80 ms (step) remaining time: 0:26:28
Epoch 1 | iter 970 step 970 | loss train: 4.961, val: 5.676 | iter time: 141.67 ms (step) remaining time: 0:26:22
Epoch 1 | iter 980 step 980 | loss train: 4.904, val: 5.676 | iter time: 140.81 ms (step) remaining time: 0:26:15
Epoch 1 | iter 990 step 990 | loss train: 4.859, val: 5.676 | iter time: 141.51 ms (step) remaining time: 0:26:09
Epoch 1 | iter 1000 step 1000 | loss train: 4.890, val: 5.676 | iter time: 142.61 ms (step) remaining time: 0:26:03
Validating ...
iter 1000: val loss 5.6617, val time: 4338.81 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00001000/lit_model.pth'
Epoch 1 | iter 1010 step 1010 | loss train: 4.909, val: 5.662 | iter time: 141.93 ms (step) remaining time: 0:27:52
Epoch 1 | iter 1020 step 1020 | loss train: 4.897, val: 5.662 | iter time: 140.82 ms (step) remaining time: 0:27:45
Epoch 1 | iter 1030 step 1030 | loss train: 4.893, val: 5.662 | iter time: 142.64 ms (step) remaining time: 0:27:38
Epoch 1 | iter 1040 step 1040 | loss train: 4.895, val: 5.662 | iter time: 140.96 ms (step) remaining time: 0:27:31
Epoch 1 | iter 1050 step 1050 | loss train: 4.896, val: 5.662 | iter time: 140.64 ms (step) remaining time: 0:27:24
Epoch 1 | iter 1060 step 1060 | loss train: 4.925, val: 5.662 | iter time: 141.91 ms (step) remaining time: 0:27:17
Epoch 1 | iter 1070 step 1070 | loss train: 4.898, val: 5.662 | iter time: 140.31 ms (step) remaining time: 0:27:10
Epoch 1 | iter 1080 step 1080 | loss train: 4.912, val: 5.662 | iter time: 140.25 ms (step) remaining time: 0:27:04
Epoch 1 | iter 1090 step 1090 | loss train: 4.951, val: 5.662 | iter time: 141.34 ms (step) remaining time: 0:26:57
Epoch 1 | iter 1100 step 1100 | loss train: 4.936, val: 5.662 | iter time: 141.52 ms (step) remaining time: 0:26:51
Validating ...
iter 1100: val loss 5.6591, val time: 4308.85 ms
Epoch 1 | iter 1110 step 1110 | loss train: 4.941, val: 5.659 | iter time: 141.93 ms (step) remaining time: 0:27:16
Epoch 1 | iter 1120 step 1120 | loss train: 4.870, val: 5.659 | iter time: 142.19 ms (step) remaining time: 0:27:09
Epoch 1 | iter 1130 step 1130 | loss train: 4.930, val: 5.659 | iter time: 141.26 ms (step) remaining time: 0:27:03
Epoch 1 | iter 1140 step 1140 | loss train: 4.902, val: 5.659 | iter time: 141.85 ms (step) remaining time: 0:26:56
Epoch 1 | iter 1150 step 1150 | loss train: 4.897, val: 5.659 | iter time: 143.01 ms (step) remaining time: 0:26:50
Epoch 1 | iter 1160 step 1160 | loss train: 4.852, val: 5.659 | iter time: 141.14 ms (step) remaining time: 0:26:44
Epoch 1 | iter 1170 step 1170 | loss train: 4.868, val: 5.659 | iter time: 141.38 ms (step) remaining time: 0:26:38
Epoch 1 | iter 1180 step 1180 | loss train: 4.836, val: 5.659 | iter time: 142.29 ms (step) remaining time: 0:26:32
Epoch 1 | iter 1190 step 1190 | loss train: 4.868, val: 5.659 | iter time: 141.88 ms (step) remaining time: 0:26:26
Epoch 1 | iter 1200 step 1200 | loss train: 4.918, val: 5.659 | iter time: 141.16 ms (step) remaining time: 0:26:20
Validating ...
iter 1200: val loss 5.6469, val time: 4280.90 ms
Epoch 1 | iter 1210 step 1210 | loss train: 4.897, val: 5.647 | iter time: 141.72 ms (step) remaining time: 0:26:42
Epoch 1 | iter 1220 step 1220 | loss train: 4.884, val: 5.647 | iter time: 141.57 ms (step) remaining time: 0:26:36
Epoch 1 | iter 1230 step 1230 | loss train: 4.859, val: 5.647 | iter time: 141.15 ms (step) remaining time: 0:26:30
Epoch 1 | iter 1240 step 1240 | loss train: 4.887, val: 5.647 | iter time: 142.04 ms (step) remaining time: 0:26:25
Epoch 1 | iter 1250 step 1250 | loss train: 4.858, val: 5.647 | iter time: 141.30 ms (step) remaining time: 0:26:19
Epoch 1 | iter 1260 step 1260 | loss train: 4.858, val: 5.647 | iter time: 142.24 ms (step) remaining time: 0:26:13
Epoch 1 | iter 1270 step 1270 | loss train: 4.857, val: 5.647 | iter time: 141.27 ms (step) remaining time: 0:26:07
Epoch 1 | iter 1280 step 1280 | loss train: 4.864, val: 5.647 | iter time: 142.10 ms (step) remaining time: 0:26:02
Epoch 1 | iter 1290 step 1290 | loss train: 4.893, val: 5.647 | iter time: 141.62 ms (step) remaining time: 0:25:56
Epoch 1 | iter 1300 step 1300 | loss train: 4.935, val: 5.647 | iter time: 142.39 ms (step) remaining time: 0:25:51
Validating ...
iter 1300: val loss 5.6410, val time: 4320.20 ms
Epoch 1 | iter 1310 step 1310 | loss train: 4.922, val: 5.641 | iter time: 141.84 ms (step) remaining time: 0:26:11
Epoch 1 | iter 1320 step 1320 | loss train: 4.868, val: 5.641 | iter time: 141.99 ms (step) remaining time: 0:26:06
Epoch 1 | iter 1330 step 1330 | loss train: 4.834, val: 5.641 | iter time: 143.18 ms (step) remaining time: 0:26:00
Epoch 1 | iter 1340 step 1340 | loss train: 4.891, val: 5.641 | iter time: 142.63 ms (step) remaining time: 0:25:55
Epoch 1 | iter 1350 step 1350 | loss train: 4.914, val: 5.641 | iter time: 141.43 ms (step) remaining time: 0:25:50
Epoch 1 | iter 1360 step 1360 | loss train: 4.895, val: 5.641 | iter time: 141.72 ms (step) remaining time: 0:25:44
Epoch 1 | iter 1370 step 1370 | loss train: 4.894, val: 5.641 | iter time: 141.68 ms (step) remaining time: 0:25:39
Epoch 1 | iter 1380 step 1380 | loss train: 4.858, val: 5.641 | iter time: 141.51 ms (step) remaining time: 0:25:34
Epoch 1 | iter 1390 step 1390 | loss train: 4.871, val: 5.641 | iter time: 142.65 ms (step) remaining time: 0:25:29
Epoch 1 | iter 1400 step 1400 | loss train: 4.886, val: 5.641 | iter time: 142.46 ms (step) remaining time: 0:25:24
Validating ...
iter 1400: val loss 5.6384, val time: 4304.92 ms
Epoch 1 | iter 1410 step 1410 | loss train: 4.873, val: 5.638 | iter time: 142.01 ms (step) remaining time: 0:25:43
Epoch 1 | iter 1420 step 1420 | loss train: 4.851, val: 5.638 | iter time: 141.44 ms (step) remaining time: 0:25:37
Epoch 1 | iter 1430 step 1430 | loss train: 4.878, val: 5.638 | iter time: 142.37 ms (step) remaining time: 0:25:32
Epoch 1 | iter 1440 step 1440 | loss train: 4.878, val: 5.638 | iter time: 142.81 ms (step) remaining time: 0:25:27
Epoch 1 | iter 1450 step 1450 | loss train: 4.861, val: 5.638 | iter time: 140.84 ms (step) remaining time: 0:25:22
Epoch 1 | iter 1460 step 1460 | loss train: 4.862, val: 5.638 | iter time: 141.78 ms (step) remaining time: 0:25:17
Epoch 1 | iter 1470 step 1470 | loss train: 4.863, val: 5.638 | iter time: 141.96 ms (step) remaining time: 0:25:12
Epoch 1 | iter 1480 step 1480 | loss train: 4.848, val: 5.638 | iter time: 141.87 ms (step) remaining time: 0:25:07
Epoch 1 | iter 1490 step 1490 | loss train: 4.871, val: 5.638 | iter time: 141.84 ms (step) remaining time: 0:25:03
Epoch 1 | iter 1500 step 1500 | loss train: 4.893, val: 5.638 | iter time: 143.67 ms (step) remaining time: 0:24:58
Validating ...
iter 1500: val loss 5.6265, val time: 4316.46 ms
Epoch 1 | iter 1510 step 1510 | loss train: 4.867, val: 5.626 | iter time: 142.82 ms (step) remaining time: 0:25:15
Epoch 1 | iter 1520 step 1520 | loss train: 4.854, val: 5.626 | iter time: 142.69 ms (step) remaining time: 0:25:10
Epoch 1 | iter 1530 step 1530 | loss train: 4.833, val: 5.626 | iter time: 142.05 ms (step) remaining time: 0:25:05
Epoch 1 | iter 1540 step 1540 | loss train: 4.863, val: 5.626 | iter time: 141.79 ms (step) remaining time: 0:25:01
Epoch 1 | iter 1550 step 1550 | loss train: 4.885, val: 5.626 | iter time: 142.52 ms (step) remaining time: 0:24:56
Epoch 1 | iter 1560 step 1560 | loss train: 4.839, val: 5.626 | iter time: 141.78 ms (step) remaining time: 0:24:51
Epoch 1 | iter 1570 step 1570 | loss train: 4.848, val: 5.626 | iter time: 142.23 ms (step) remaining time: 0:24:47
Epoch 1 | iter 1580 step 1580 | loss train: 4.854, val: 5.626 | iter time: 143.34 ms (step) remaining time: 0:24:42
Epoch 1 | iter 1590 step 1590 | loss train: 4.881, val: 5.626 | iter time: 142.09 ms (step) remaining time: 0:24:38
Epoch 2 | iter 1600 step 1600 | loss train: 4.876, val: 5.626 | iter time: 142.21 ms (step) remaining time: 0:24:34
Validating ...
iter 1600: val loss 5.6249, val time: 4312.43 ms
Epoch 2 | iter 1610 step 1610 | loss train: 4.848, val: 5.625 | iter time: 142.87 ms (step) remaining time: 0:24:50
Epoch 2 | iter 1620 step 1620 | loss train: 4.877, val: 5.625 | iter time: 142.22 ms (step) remaining time: 0:24:45
Epoch 2 | iter 1630 step 1630 | loss train: 4.773, val: 5.625 | iter time: 142.82 ms (step) remaining time: 0:24:40
Epoch 2 | iter 1640 step 1640 | loss train: 4.858, val: 5.625 | iter time: 143.04 ms (step) remaining time: 0:24:36
Epoch 2 | iter 1650 step 1650 | loss train: 4.831, val: 5.625 | iter time: 142.17 ms (step) remaining time: 0:24:33
Epoch 2 | iter 1660 step 1660 | loss train: 4.878, val: 5.625 | iter time: 143.12 ms (step) remaining time: 0:24:28
Epoch 2 | iter 1670 step 1670 | loss train: 4.865, val: 5.625 | iter time: 142.15 ms (step) remaining time: 0:24:24
Epoch 2 | iter 1680 step 1680 | loss train: 4.775, val: 5.625 | iter time: 141.26 ms (step) remaining time: 0:24:19
Epoch 2 | iter 1690 step 1690 | loss train: 4.853, val: 5.625 | iter time: 141.56 ms (step) remaining time: 0:24:15
Epoch 2 | iter 1700 step 1700 | loss train: 4.881, val: 5.625 | iter time: 142.72 ms (step) remaining time: 0:24:11
Validating ...
iter 1700: val loss 5.6185, val time: 4317.68 ms
Epoch 2 | iter 1710 step 1710 | loss train: 4.859, val: 5.619 | iter time: 142.06 ms (step) remaining time: 0:24:25
Epoch 2 | iter 1720 step 1720 | loss train: 4.804, val: 5.619 | iter time: 143.08 ms (step) remaining time: 0:24:21
Epoch 2 | iter 1730 step 1730 | loss train: 4.831, val: 5.619 | iter time: 143.25 ms (step) remaining time: 0:24:17
Epoch 2 | iter 1740 step 1740 | loss train: 4.871, val: 5.619 | iter time: 142.93 ms (step) remaining time: 0:24:12
Epoch 2 | iter 1750 step 1750 | loss train: 4.800, val: 5.619 | iter time: 141.50 ms (step) remaining time: 0:24:08
Epoch 2 | iter 1760 step 1760 | loss train: 4.855, val: 5.619 | iter time: 142.65 ms (step) remaining time: 0:24:04
Epoch 2 | iter 1770 step 1770 | loss train: 4.841, val: 5.619 | iter time: 141.72 ms (step) remaining time: 0:24:00
Epoch 2 | iter 1780 step 1780 | loss train: 4.859, val: 5.619 | iter time: 142.15 ms (step) remaining time: 0:23:55
Epoch 2 | iter 1790 step 1790 | loss train: 4.845, val: 5.619 | iter time: 141.94 ms (step) remaining time: 0:23:51
Epoch 2 | iter 1800 step 1800 | loss train: 4.872, val: 5.619 | iter time: 142.56 ms (step) remaining time: 0:23:47
Validating ...
iter 1800: val loss 5.6254, val time: 4326.63 ms
Epoch 2 | iter 1810 step 1810 | loss train: 4.830, val: 5.625 | iter time: 141.41 ms (step) remaining time: 0:24:01
Epoch 2 | iter 1820 step 1820 | loss train: 4.851, val: 5.625 | iter time: 142.43 ms (step) remaining time: 0:23:56
Epoch 2 | iter 1830 step 1830 | loss train: 4.854, val: 5.625 | iter time: 141.39 ms (step) remaining time: 0:23:52
Epoch 2 | iter 1840 step 1840 | loss train: 4.856, val: 5.625 | iter time: 142.28 ms (step) remaining time: 0:23:48
Epoch 2 | iter 1850 step 1850 | loss train: 4.814, val: 5.625 | iter time: 141.86 ms (step) remaining time: 0:23:44
Epoch 2 | iter 1860 step 1860 | loss train: 4.816, val: 5.625 | iter time: 142.24 ms (step) remaining time: 0:23:40
Epoch 2 | iter 1870 step 1870 | loss train: 4.837, val: 5.625 | iter time: 141.72 ms (step) remaining time: 0:23:36
Epoch 2 | iter 1880 step 1880 | loss train: 4.890, val: 5.625 | iter time: 143.18 ms (step) remaining time: 0:23:32
Epoch 2 | iter 1890 step 1890 | loss train: 4.859, val: 5.625 | iter time: 142.13 ms (step) remaining time: 0:23:28
Epoch 2 | iter 1900 step 1900 | loss train: 4.852, val: 5.625 | iter time: 141.52 ms (step) remaining time: 0:23:24
Validating ...
iter 1900: val loss 5.6231, val time: 4295.41 ms
Epoch 2 | iter 1910 step 1910 | loss train: 4.844, val: 5.623 | iter time: 141.84 ms (step) remaining time: 0:23:36
Epoch 2 | iter 1920 step 1920 | loss train: 4.825, val: 5.623 | iter time: 141.86 ms (step) remaining time: 0:23:32
Epoch 2 | iter 1930 step 1930 | loss train: 4.857, val: 5.623 | iter time: 142.92 ms (step) remaining time: 0:23:28
Epoch 2 | iter 1940 step 1940 | loss train: 4.883, val: 5.623 | iter time: 143.08 ms (step) remaining time: 0:23:24
Epoch 2 | iter 1950 step 1950 | loss train: 4.852, val: 5.623 | iter time: 141.54 ms (step) remaining time: 0:23:21
Epoch 2 | iter 1960 step 1960 | loss train: 4.846, val: 5.623 | iter time: 142.74 ms (step) remaining time: 0:23:17
Epoch 2 | iter 1970 step 1970 | loss train: 4.811, val: 5.623 | iter time: 142.89 ms (step) remaining time: 0:23:13
Epoch 2 | iter 1980 step 1980 | loss train: 4.880, val: 5.623 | iter time: 141.18 ms (step) remaining time: 0:23:09
Epoch 2 | iter 1990 step 1990 | loss train: 4.872, val: 5.623 | iter time: 141.95 ms (step) remaining time: 0:23:05
Epoch 2 | iter 2000 step 2000 | loss train: 4.848, val: 5.623 | iter time: 142.30 ms (step) remaining time: 0:23:01
Validating ...
iter 2000: val loss 5.6194, val time: 4299.82 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00002000/lit_model.pth'
Epoch 2 | iter 2010 step 2010 | loss train: 4.831, val: 5.619 | iter time: 141.34 ms (step) remaining time: 0:23:47
Epoch 2 | iter 2020 step 2020 | loss train: 4.867, val: 5.619 | iter time: 142.04 ms (step) remaining time: 0:23:43
Epoch 2 | iter 2030 step 2030 | loss train: 4.857, val: 5.619 | iter time: 141.90 ms (step) remaining time: 0:23:39
Epoch 2 | iter 2040 step 2040 | loss train: 4.898, val: 5.619 | iter time: 142.19 ms (step) remaining time: 0:23:35
Epoch 2 | iter 2050 step 2050 | loss train: 4.820, val: 5.619 | iter time: 141.53 ms (step) remaining time: 0:23:31
Epoch 2 | iter 2060 step 2060 | loss train: 4.844, val: 5.619 | iter time: 142.20 ms (step) remaining time: 0:23:27
Epoch 2 | iter 2070 step 2070 | loss train: 4.848, val: 5.619 | iter time: 141.75 ms (step) remaining time: 0:23:23
Epoch 2 | iter 2080 step 2080 | loss train: 4.834, val: 5.619 | iter time: 141.52 ms (step) remaining time: 0:23:19
Epoch 2 | iter 2090 step 2090 | loss train: 4.875, val: 5.619 | iter time: 142.07 ms (step) remaining time: 0:23:15
Epoch 2 | iter 2100 step 2100 | loss train: 4.845, val: 5.619 | iter time: 141.37 ms (step) remaining time: 0:23:12
Validating ...
iter 2100: val loss 5.6203, val time: 4302.37 ms
Epoch 2 | iter 2110 step 2110 | loss train: 4.831, val: 5.620 | iter time: 141.51 ms (step) remaining time: 0:23:22
Epoch 2 | iter 2120 step 2120 | loss train: 4.812, val: 5.620 | iter time: 141.49 ms (step) remaining time: 0:23:18
Epoch 2 | iter 2130 step 2130 | loss train: 4.821, val: 5.620 | iter time: 141.48 ms (step) remaining time: 0:23:14
Epoch 2 | iter 2140 step 2140 | loss train: 4.862, val: 5.620 | iter time: 142.15 ms (step) remaining time: 0:23:10
Epoch 2 | iter 2150 step 2150 | loss train: 4.815, val: 5.620 | iter time: 142.26 ms (step) remaining time: 0:23:07
Epoch 2 | iter 2160 step 2160 | loss train: 4.819, val: 5.620 | iter time: 141.43 ms (step) remaining time: 0:23:03
Epoch 2 | iter 2170 step 2170 | loss train: 4.867, val: 5.620 | iter time: 141.90 ms (step) remaining time: 0:22:59
Epoch 2 | iter 2180 step 2180 | loss train: 4.808, val: 5.620 | iter time: 142.35 ms (step) remaining time: 0:22:55
Epoch 2 | iter 2190 step 2190 | loss train: 4.832, val: 5.620 | iter time: 142.37 ms (step) remaining time: 0:22:51
Epoch 2 | iter 2200 step 2200 | loss train: 4.833, val: 5.620 | iter time: 141.19 ms (step) remaining time: 0:22:48
Validating ...
iter 2200: val loss 5.6091, val time: 4323.54 ms
Epoch 2 | iter 2210 step 2210 | loss train: 4.808, val: 5.609 | iter time: 142.39 ms (step) remaining time: 0:22:57
Epoch 2 | iter 2220 step 2220 | loss train: 4.848, val: 5.609 | iter time: 141.29 ms (step) remaining time: 0:22:54
Epoch 2 | iter 2230 step 2230 | loss train: 4.839, val: 5.609 | iter time: 141.40 ms (step) remaining time: 0:22:50
Epoch 2 | iter 2240 step 2240 | loss train: 4.826, val: 5.609 | iter time: 141.25 ms (step) remaining time: 0:22:46
Epoch 2 | iter 2250 step 2250 | loss train: 4.832, val: 5.609 | iter time: 142.22 ms (step) remaining time: 0:22:42
Epoch 2 | iter 2260 step 2260 | loss train: 4.847, val: 5.609 | iter time: 141.72 ms (step) remaining time: 0:22:39
Epoch 2 | iter 2270 step 2270 | loss train: 4.862, val: 5.609 | iter time: 141.73 ms (step) remaining time: 0:22:35
Epoch 2 | iter 2280 step 2280 | loss train: 4.806, val: 5.609 | iter time: 142.54 ms (step) remaining time: 0:22:31
Epoch 2 | iter 2290 step 2290 | loss train: 4.866, val: 5.609 | iter time: 141.90 ms (step) remaining time: 0:22:28
Epoch 2 | iter 2300 step 2300 | loss train: 4.831, val: 5.609 | iter time: 141.55 ms (step) remaining time: 0:22:24
Validating ...
iter 2300: val loss 5.6117, val time: 4332.80 ms
Epoch 2 | iter 2310 step 2310 | loss train: 4.865, val: 5.612 | iter time: 142.36 ms (step) remaining time: 0:22:33
Epoch 2 | iter 2320 step 2320 | loss train: 4.861, val: 5.612 | iter time: 141.97 ms (step) remaining time: 0:22:30
Epoch 2 | iter 2330 step 2330 | loss train: 4.847, val: 5.612 | iter time: 142.69 ms (step) remaining time: 0:22:26
Epoch 2 | iter 2340 step 2340 | loss train: 4.754, val: 5.612 | iter time: 140.82 ms (step) remaining time: 0:22:23
Epoch 2 | iter 2350 step 2350 | loss train: 4.821, val: 5.612 | iter time: 141.59 ms (step) remaining time: 0:22:19
Epoch 2 | iter 2360 step 2360 | loss train: 4.828, val: 5.612 | iter time: 141.18 ms (step) remaining time: 0:22:15
Epoch 2 | iter 2370 step 2370 | loss train: 4.832, val: 5.612 | iter time: 142.51 ms (step) remaining time: 0:22:12
Epoch 2 | iter 2380 step 2380 | loss train: 4.836, val: 5.612 | iter time: 141.63 ms (step) remaining time: 0:22:08
Epoch 2 | iter 2390 step 2390 | loss train: 4.846, val: 5.612 | iter time: 143.01 ms (step) remaining time: 0:22:05
Epoch 2 | iter 2400 step 2400 | loss train: 4.852, val: 5.612 | iter time: 142.12 ms (step) remaining time: 0:22:01
Validating ...
iter 2400: val loss 5.6100, val time: 4307.44 ms
Epoch 2 | iter 2410 step 2410 | loss train: 4.814, val: 5.610 | iter time: 143.29 ms (step) remaining time: 0:22:10
Epoch 2 | iter 2420 step 2420 | loss train: 4.818, val: 5.610 | iter time: 142.44 ms (step) remaining time: 0:22:06
Epoch 2 | iter 2430 step 2430 | loss train: 4.845, val: 5.610 | iter time: 142.05 ms (step) remaining time: 0:22:03
Epoch 2 | iter 2440 step 2440 | loss train: 4.783, val: 5.610 | iter time: 141.72 ms (step) remaining time: 0:21:59
Epoch 2 | iter 2450 step 2450 | loss train: 4.813, val: 5.610 | iter time: 142.13 ms (step) remaining time: 0:21:56
Epoch 2 | iter 2460 step 2460 | loss train: 4.840, val: 5.610 | iter time: 142.97 ms (step) remaining time: 0:21:52
Epoch 2 | iter 2470 step 2470 | loss train: 4.818, val: 5.610 | iter time: 143.29 ms (step) remaining time: 0:21:49
Epoch 2 | iter 2480 step 2480 | loss train: 4.827, val: 5.610 | iter time: 141.82 ms (step) remaining time: 0:21:45
Epoch 2 | iter 2490 step 2490 | loss train: 4.858, val: 5.610 | iter time: 142.55 ms (step) remaining time: 0:21:42
Epoch 2 | iter 2500 step 2500 | loss train: 4.812, val: 5.610 | iter time: 143.22 ms (step) remaining time: 0:21:39
Validating ...
iter 2500: val loss 5.6041, val time: 4329.59 ms
Epoch 2 | iter 2510 step 2510 | loss train: 4.822, val: 5.604 | iter time: 141.57 ms (step) remaining time: 0:21:47
Epoch 2 | iter 2520 step 2520 | loss train: 4.744, val: 5.604 | iter time: 142.71 ms (step) remaining time: 0:21:43
Epoch 2 | iter 2530 step 2530 | loss train: 4.807, val: 5.604 | iter time: 141.88 ms (step) remaining time: 0:21:40
Epoch 2 | iter 2540 step 2540 | loss train: 4.835, val: 5.604 | iter time: 141.33 ms (step) remaining time: 0:21:36
Epoch 2 | iter 2550 step 2550 | loss train: 4.848, val: 5.604 | iter time: 142.70 ms (step) remaining time: 0:21:33
Epoch 2 | iter 2560 step 2560 | loss train: 4.830, val: 5.604 | iter time: 141.81 ms (step) remaining time: 0:21:30
Epoch 2 | iter 2570 step 2570 | loss train: 4.829, val: 5.604 | iter time: 142.27 ms (step) remaining time: 0:21:26
Epoch 2 | iter 2580 step 2580 | loss train: 4.817, val: 5.604 | iter time: 141.30 ms (step) remaining time: 0:21:23
Epoch 2 | iter 2590 step 2590 | loss train: 4.838, val: 5.604 | iter time: 141.90 ms (step) remaining time: 0:21:20
Epoch 2 | iter 2600 step 2600 | loss train: 4.843, val: 5.604 | iter time: 141.60 ms (step) remaining time: 0:21:16
Validating ...
iter 2600: val loss 5.6031, val time: 4319.92 ms
Epoch 2 | iter 2610 step 2610 | loss train: 4.858, val: 5.603 | iter time: 141.84 ms (step) remaining time: 0:21:24
Epoch 2 | iter 2620 step 2620 | loss train: 4.799, val: 5.603 | iter time: 142.59 ms (step) remaining time: 0:21:21
Epoch 2 | iter 2630 step 2630 | loss train: 4.834, val: 5.603 | iter time: 142.96 ms (step) remaining time: 0:21:17
Epoch 2 | iter 2640 step 2640 | loss train: 4.847, val: 5.603 | iter time: 142.90 ms (step) remaining time: 0:21:14
Epoch 2 | iter 2650 step 2650 | loss train: 4.805, val: 5.603 | iter time: 142.08 ms (step) remaining time: 0:21:11
Epoch 2 | iter 2660 step 2660 | loss train: 4.816, val: 5.603 | iter time: 142.08 ms (step) remaining time: 0:21:07
Epoch 2 | iter 2670 step 2670 | loss train: 4.786, val: 5.603 | iter time: 142.21 ms (step) remaining time: 0:21:04
Epoch 2 | iter 2680 step 2680 | loss train: 4.840, val: 5.603 | iter time: 141.42 ms (step) remaining time: 0:21:01
Epoch 2 | iter 2690 step 2690 | loss train: 4.835, val: 5.603 | iter time: 142.31 ms (step) remaining time: 0:20:58
Epoch 2 | iter 2700 step 2700 | loss train: 4.816, val: 5.603 | iter time: 142.47 ms (step) remaining time: 0:20:54
Validating ...
iter 2700: val loss 5.6024, val time: 4541.62 ms
Epoch 2 | iter 2710 step 2710 | loss train: 4.872, val: 5.602 | iter time: 142.30 ms (step) remaining time: 0:21:02
Epoch 2 | iter 2720 step 2720 | loss train: 4.790, val: 5.602 | iter time: 142.80 ms (step) remaining time: 0:20:59
Epoch 2 | iter 2730 step 2730 | loss train: 4.832, val: 5.602 | iter time: 142.06 ms (step) remaining time: 0:20:56
Epoch 2 | iter 2740 step 2740 | loss train: 4.829, val: 5.602 | iter time: 141.15 ms (step) remaining time: 0:20:52
Epoch 2 | iter 2750 step 2750 | loss train: 4.795, val: 5.602 | iter time: 142.01 ms (step) remaining time: 0:20:49
Epoch 2 | iter 2760 step 2760 | loss train: 4.835, val: 5.602 | iter time: 142.56 ms (step) remaining time: 0:20:46
Epoch 2 | iter 2770 step 2770 | loss train: 4.871, val: 5.602 | iter time: 142.48 ms (step) remaining time: 0:20:43
Epoch 2 | iter 2780 step 2780 | loss train: 4.804, val: 5.602 | iter time: 142.75 ms (step) remaining time: 0:20:40
Epoch 2 | iter 2790 step 2790 | loss train: 4.766, val: 5.602 | iter time: 142.55 ms (step) remaining time: 0:20:36
Epoch 2 | iter 2800 step 2800 | loss train: 4.856, val: 5.602 | iter time: 142.78 ms (step) remaining time: 0:20:33
Validating ...
iter 2800: val loss 5.5926, val time: 4323.07 ms
Epoch 2 | iter 2810 step 2810 | loss train: 4.770, val: 5.593 | iter time: 142.55 ms (step) remaining time: 0:20:40
Epoch 2 | iter 2820 step 2820 | loss train: 4.860, val: 5.593 | iter time: 141.88 ms (step) remaining time: 0:20:37
Epoch 2 | iter 2830 step 2830 | loss train: 4.815, val: 5.593 | iter time: 142.66 ms (step) remaining time: 0:20:33
Epoch 2 | iter 2840 step 2840 | loss train: 4.828, val: 5.593 | iter time: 141.96 ms (step) remaining time: 0:20:30
Epoch 2 | iter 2850 step 2850 | loss train: 4.829, val: 5.593 | iter time: 142.12 ms (step) remaining time: 0:20:27
Epoch 2 | iter 2860 step 2860 | loss train: 4.843, val: 5.593 | iter time: 142.19 ms (step) remaining time: 0:20:24
Epoch 2 | iter 2870 step 2870 | loss train: 4.854, val: 5.593 | iter time: 142.80 ms (step) remaining time: 0:20:21
Epoch 2 | iter 2880 step 2880 | loss train: 4.815, val: 5.593 | iter time: 142.39 ms (step) remaining time: 0:20:18
Epoch 2 | iter 2890 step 2890 | loss train: 4.846, val: 5.593 | iter time: 142.64 ms (step) remaining time: 0:20:15
Epoch 2 | iter 2900 step 2900 | loss train: 4.798, val: 5.593 | iter time: 141.35 ms (step) remaining time: 0:20:12
Validating ...
iter 2900: val loss 5.5996, val time: 4309.21 ms
Epoch 2 | iter 2910 step 2910 | loss train: 4.880, val: 5.600 | iter time: 143.31 ms (step) remaining time: 0:20:18
Epoch 2 | iter 2920 step 2920 | loss train: 4.840, val: 5.600 | iter time: 142.09 ms (step) remaining time: 0:20:15
Epoch 2 | iter 2930 step 2930 | loss train: 4.813, val: 5.600 | iter time: 141.71 ms (step) remaining time: 0:20:12
Epoch 2 | iter 2940 step 2940 | loss train: 4.806, val: 5.600 | iter time: 142.32 ms (step) remaining time: 0:20:09
Epoch 2 | iter 2950 step 2950 | loss train: 4.831, val: 5.600 | iter time: 141.71 ms (step) remaining time: 0:20:06
Epoch 2 | iter 2960 step 2960 | loss train: 4.806, val: 5.600 | iter time: 143.03 ms (step) remaining time: 0:20:03
Epoch 2 | iter 2970 step 2970 | loss train: 4.848, val: 5.600 | iter time: 143.21 ms (step) remaining time: 0:20:00
Epoch 2 | iter 2980 step 2980 | loss train: 4.845, val: 5.600 | iter time: 142.55 ms (step) remaining time: 0:19:56
Epoch 2 | iter 2990 step 2990 | loss train: 4.829, val: 5.600 | iter time: 141.99 ms (step) remaining time: 0:19:53
Epoch 2 | iter 3000 step 3000 | loss train: 4.858, val: 5.600 | iter time: 141.65 ms (step) remaining time: 0:19:50
Validating ...
iter 3000: val loss 5.5936, val time: 4308.50 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00003000/lit_model.pth'
Epoch 2 | iter 3010 step 3010 | loss train: 4.811, val: 5.594 | iter time: 141.43 ms (step) remaining time: 0:20:16
Epoch 2 | iter 3020 step 3020 | loss train: 4.847, val: 5.594 | iter time: 141.05 ms (step) remaining time: 0:20:13
Epoch 2 | iter 3030 step 3030 | loss train: 4.869, val: 5.594 | iter time: 140.87 ms (step) remaining time: 0:20:10
Epoch 2 | iter 3040 step 3040 | loss train: 4.848, val: 5.594 | iter time: 142.07 ms (step) remaining time: 0:20:07
Epoch 2 | iter 3050 step 3050 | loss train: 4.802, val: 5.594 | iter time: 141.45 ms (step) remaining time: 0:20:03
Epoch 2 | iter 3060 step 3060 | loss train: 4.798, val: 5.594 | iter time: 142.14 ms (step) remaining time: 0:20:00
Epoch 2 | iter 3070 step 3070 | loss train: 4.830, val: 5.594 | iter time: 141.89 ms (step) remaining time: 0:19:57
Epoch 2 | iter 3080 step 3080 | loss train: 4.822, val: 5.594 | iter time: 141.40 ms (step) remaining time: 0:19:54
Epoch 2 | iter 3090 step 3090 | loss train: 4.740, val: 5.594 | iter time: 142.07 ms (step) remaining time: 0:19:51
Epoch 2 | iter 3100 step 3100 | loss train: 4.824, val: 5.594 | iter time: 141.97 ms (step) remaining time: 0:19:48
Validating ...
iter 3100: val loss 5.5940, val time: 4315.31 ms
Epoch 2 | iter 3110 step 3110 | loss train: 4.810, val: 5.594 | iter time: 141.70 ms (step) remaining time: 0:19:53
Epoch 2 | iter 3120 step 3120 | loss train: 4.817, val: 5.594 | iter time: 141.81 ms (step) remaining time: 0:19:50
Epoch 2 | iter 3130 step 3130 | loss train: 4.803, val: 5.594 | iter time: 142.50 ms (step) remaining time: 0:19:47
Epoch 2 | iter 3140 step 3140 | loss train: 4.795, val: 5.594 | iter time: 142.27 ms (step) remaining time: 0:19:44
Epoch 2 | iter 3150 step 3150 | loss train: 4.866, val: 5.594 | iter time: 140.85 ms (step) remaining time: 0:19:41
Epoch 2 | iter 3160 step 3160 | loss train: 4.772, val: 5.594 | iter time: 141.49 ms (step) remaining time: 0:19:38
Epoch 2 | iter 3170 step 3170 | loss train: 4.841, val: 5.594 | iter time: 141.30 ms (step) remaining time: 0:19:35
Epoch 2 | iter 3180 step 3180 | loss train: 4.808, val: 5.594 | iter time: 141.64 ms (step) remaining time: 0:19:32
Epoch 2 | iter 3190 step 3190 | loss train: 4.834, val: 5.594 | iter time: 141.61 ms (step) remaining time: 0:19:29
Epoch 3 | iter 3200 step 3200 | loss train: 4.751, val: 5.594 | iter time: 141.56 ms (step) remaining time: 0:19:26
Validating ...
iter 3200: val loss 5.5948, val time: 4298.67 ms
Epoch 3 | iter 3210 step 3210 | loss train: 4.767, val: 5.595 | iter time: 142.59 ms (step) remaining time: 0:19:31
Epoch 3 | iter 3220 step 3220 | loss train: 4.719, val: 5.595 | iter time: 142.76 ms (step) remaining time: 0:19:28
Epoch 3 | iter 3230 step 3230 | loss train: 4.721, val: 5.595 | iter time: 141.32 ms (step) remaining time: 0:19:25
Epoch 3 | iter 3240 step 3240 | loss train: 4.820, val: 5.595 | iter time: 141.98 ms (step) remaining time: 0:19:22
Epoch 3 | iter 3250 step 3250 | loss train: 4.795, val: 5.595 | iter time: 141.32 ms (step) remaining time: 0:19:20
Epoch 3 | iter 3260 step 3260 | loss train: 4.767, val: 5.595 | iter time: 143.55 ms (step) remaining time: 0:19:17
Epoch 3 | iter 3270 step 3270 | loss train: 4.784, val: 5.595 | iter time: 141.58 ms (step) remaining time: 0:19:14
Epoch 3 | iter 3280 step 3280 | loss train: 4.801, val: 5.595 | iter time: 142.24 ms (step) remaining time: 0:19:11
Epoch 3 | iter 3290 step 3290 | loss train: 4.734, val: 5.595 | iter time: 141.70 ms (step) remaining time: 0:19:08
Epoch 3 | iter 3300 step 3300 | loss train: 4.816, val: 5.595 | iter time: 141.66 ms (step) remaining time: 0:19:05
Validating ...
iter 3300: val loss 5.5874, val time: 4308.57 ms
Epoch 3 | iter 3310 step 3310 | loss train: 4.825, val: 5.587 | iter time: 142.22 ms (step) remaining time: 0:19:09
Epoch 3 | iter 3320 step 3320 | loss train: 4.753, val: 5.587 | iter time: 142.91 ms (step) remaining time: 0:19:07
Epoch 3 | iter 3330 step 3330 | loss train: 4.817, val: 5.587 | iter time: 142.56 ms (step) remaining time: 0:19:04
Epoch 3 | iter 3340 step 3340 | loss train: 4.772, val: 5.587 | iter time: 142.41 ms (step) remaining time: 0:19:01
Epoch 3 | iter 3350 step 3350 | loss train: 4.747, val: 5.587 | iter time: 141.86 ms (step) remaining time: 0:18:58
Epoch 3 | iter 3360 step 3360 | loss train: 4.794, val: 5.587 | iter time: 142.28 ms (step) remaining time: 0:18:55
Epoch 3 | iter 3370 step 3370 | loss train: 4.793, val: 5.587 | iter time: 141.89 ms (step) remaining time: 0:18:52
Epoch 3 | iter 3380 step 3380 | loss train: 4.781, val: 5.587 | iter time: 141.87 ms (step) remaining time: 0:18:49
Epoch 3 | iter 3390 step 3390 | loss train: 4.754, val: 5.587 | iter time: 141.43 ms (step) remaining time: 0:18:46
Epoch 3 | iter 3400 step 3400 | loss train: 4.739, val: 5.587 | iter time: 143.62 ms (step) remaining time: 0:18:43
Validating ...
iter 3400: val loss 5.5917, val time: 4314.68 ms
Epoch 3 | iter 3410 step 3410 | loss train: 4.740, val: 5.592 | iter time: 142.60 ms (step) remaining time: 0:18:48
Epoch 3 | iter 3420 step 3420 | loss train: 4.737, val: 5.592 | iter time: 143.04 ms (step) remaining time: 0:18:45
Epoch 3 | iter 3430 step 3430 | loss train: 4.778, val: 5.592 | iter time: 143.59 ms (step) remaining time: 0:18:42
Epoch 3 | iter 3440 step 3440 | loss train: 4.790, val: 5.592 | iter time: 144.19 ms (step) remaining time: 0:18:39
Epoch 3 | iter 3450 step 3450 | loss train: 4.779, val: 5.592 | iter time: 142.85 ms (step) remaining time: 0:18:36
Epoch 3 | iter 3460 step 3460 | loss train: 4.824, val: 5.592 | iter time: 142.03 ms (step) remaining time: 0:18:33
Epoch 3 | iter 3470 step 3470 | loss train: 4.766, val: 5.592 | iter time: 141.61 ms (step) remaining time: 0:18:31
Epoch 3 | iter 3480 step 3480 | loss train: 4.789, val: 5.592 | iter time: 142.88 ms (step) remaining time: 0:18:28
Epoch 3 | iter 3490 step 3490 | loss train: 4.807, val: 5.592 | iter time: 142.39 ms (step) remaining time: 0:18:25
Epoch 3 | iter 3500 step 3500 | loss train: 4.771, val: 5.592 | iter time: 143.36 ms (step) remaining time: 0:18:22
Validating ...
iter 3500: val loss 5.5883, val time: 4301.68 ms
Epoch 3 | iter 3510 step 3510 | loss train: 4.799, val: 5.588 | iter time: 141.96 ms (step) remaining time: 0:18:26
Epoch 3 | iter 3520 step 3520 | loss train: 4.817, val: 5.588 | iter time: 142.98 ms (step) remaining time: 0:18:23
Epoch 3 | iter 3530 step 3530 | loss train: 4.821, val: 5.588 | iter time: 142.14 ms (step) remaining time: 0:18:20
Epoch 3 | iter 3540 step 3540 | loss train: 4.740, val: 5.588 | iter time: 141.53 ms (step) remaining time: 0:18:18
Epoch 3 | iter 3550 step 3550 | loss train: 4.806, val: 5.588 | iter time: 142.73 ms (step) remaining time: 0:18:15
Epoch 3 | iter 3560 step 3560 | loss train: 4.786, val: 5.588 | iter time: 143.26 ms (step) remaining time: 0:18:12
Epoch 3 | iter 3570 step 3570 | loss train: 4.758, val: 5.588 | iter time: 141.93 ms (step) remaining time: 0:18:09
Epoch 3 | iter 3580 step 3580 | loss train: 4.797, val: 5.588 | iter time: 141.92 ms (step) remaining time: 0:18:06
Epoch 3 | iter 3590 step 3590 | loss train: 4.769, val: 5.588 | iter time: 142.22 ms (step) remaining time: 0:18:04
Epoch 3 | iter 3600 step 3600 | loss train: 4.803, val: 5.588 | iter time: 142.23 ms (step) remaining time: 0:18:01
Validating ...
iter 3600: val loss 5.5911, val time: 4312.92 ms
Epoch 3 | iter 3610 step 3610 | loss train: 4.788, val: 5.591 | iter time: 141.92 ms (step) remaining time: 0:18:05
Epoch 3 | iter 3620 step 3620 | loss train: 4.796, val: 5.591 | iter time: 142.84 ms (step) remaining time: 0:18:02
Epoch 3 | iter 3630 step 3630 | loss train: 4.763, val: 5.591 | iter time: 143.15 ms (step) remaining time: 0:17:59
Epoch 3 | iter 3640 step 3640 | loss train: 4.795, val: 5.591 | iter time: 142.22 ms (step) remaining time: 0:17:56
Epoch 3 | iter 3650 step 3650 | loss train: 4.786, val: 5.591 | iter time: 141.05 ms (step) remaining time: 0:17:54
Epoch 3 | iter 3660 step 3660 | loss train: 4.836, val: 5.591 | iter time: 141.91 ms (step) remaining time: 0:17:51
Epoch 3 | iter 3670 step 3670 | loss train: 4.824, val: 5.591 | iter time: 142.29 ms (step) remaining time: 0:17:48
Epoch 3 | iter 3680 step 3680 | loss train: 4.779, val: 5.591 | iter time: 142.04 ms (step) remaining time: 0:17:45
Epoch 3 | iter 3690 step 3690 | loss train: 4.750, val: 5.591 | iter time: 142.96 ms (step) remaining time: 0:17:43
Epoch 3 | iter 3700 step 3700 | loss train: 4.796, val: 5.591 | iter time: 142.70 ms (step) remaining time: 0:17:40
Validating ...
iter 3700: val loss 5.5876, val time: 4333.91 ms
Epoch 3 | iter 3710 step 3710 | loss train: 4.781, val: 5.588 | iter time: 143.54 ms (step) remaining time: 0:17:44
Epoch 3 | iter 3720 step 3720 | loss train: 4.774, val: 5.588 | iter time: 141.84 ms (step) remaining time: 0:17:41
Epoch 3 | iter 3730 step 3730 | loss train: 4.828, val: 5.588 | iter time: 142.55 ms (step) remaining time: 0:17:38
Epoch 3 | iter 3740 step 3740 | loss train: 4.764, val: 5.588 | iter time: 141.86 ms (step) remaining time: 0:17:35
Epoch 3 | iter 3750 step 3750 | loss train: 4.769, val: 5.588 | iter time: 143.49 ms (step) remaining time: 0:17:33
Epoch 3 | iter 3760 step 3760 | loss train: 4.796, val: 5.588 | iter time: 142.69 ms (step) remaining time: 0:17:30
Epoch 3 | iter 3770 step 3770 | loss train: 4.766, val: 5.588 | iter time: 141.16 ms (step) remaining time: 0:17:28
Epoch 3 | iter 3780 step 3780 | loss train: 4.815, val: 5.588 | iter time: 142.75 ms (step) remaining time: 0:17:25
Epoch 3 | iter 3790 step 3790 | loss train: 4.844, val: 5.588 | iter time: 141.69 ms (step) remaining time: 0:17:22
Epoch 3 | iter 3800 step 3800 | loss train: 4.769, val: 5.588 | iter time: 142.32 ms (step) remaining time: 0:17:19
Validating ...
iter 3800: val loss 5.5851, val time: 4314.66 ms
Epoch 3 | iter 3810 step 3810 | loss train: 4.787, val: 5.585 | iter time: 142.76 ms (step) remaining time: 0:17:23
Epoch 3 | iter 3820 step 3820 | loss train: 4.812, val: 5.585 | iter time: 142.50 ms (step) remaining time: 0:17:20
Epoch 3 | iter 3830 step 3830 | loss train: 4.825, val: 5.585 | iter time: 141.60 ms (step) remaining time: 0:17:17
Epoch 3 | iter 3840 step 3840 | loss train: 4.814, val: 5.585 | iter time: 142.15 ms (step) remaining time: 0:17:15
Epoch 3 | iter 3850 step 3850 | loss train: 4.753, val: 5.585 | iter time: 140.89 ms (step) remaining time: 0:17:12
Epoch 3 | iter 3860 step 3860 | loss train: 4.815, val: 5.585 | iter time: 142.21 ms (step) remaining time: 0:17:09
Epoch 3 | iter 3870 step 3870 | loss train: 4.832, val: 5.585 | iter time: 142.43 ms (step) remaining time: 0:17:07
Epoch 3 | iter 3880 step 3880 | loss train: 4.801, val: 5.585 | iter time: 141.85 ms (step) remaining time: 0:17:04
Epoch 3 | iter 3890 step 3890 | loss train: 4.759, val: 5.585 | iter time: 142.22 ms (step) remaining time: 0:17:01
Epoch 3 | iter 3900 step 3900 | loss train: 4.801, val: 5.585 | iter time: 141.84 ms (step) remaining time: 0:16:59
Validating ...
iter 3900: val loss 5.5877, val time: 4306.04 ms
Epoch 3 | iter 3910 step 3910 | loss train: 4.812, val: 5.588 | iter time: 142.72 ms (step) remaining time: 0:17:02
Epoch 3 | iter 3920 step 3920 | loss train: 4.760, val: 5.588 | iter time: 143.49 ms (step) remaining time: 0:16:59
Epoch 3 | iter 3930 step 3930 | loss train: 4.782, val: 5.588 | iter time: 142.98 ms (step) remaining time: 0:16:57
Epoch 3 | iter 3940 step 3940 | loss train: 4.782, val: 5.588 | iter time: 143.10 ms (step) remaining time: 0:16:54
Epoch 3 | iter 3950 step 3950 | loss train: 4.806, val: 5.588 | iter time: 141.72 ms (step) remaining time: 0:16:51
Epoch 3 | iter 3960 step 3960 | loss train: 4.795, val: 5.588 | iter time: 142.21 ms (step) remaining time: 0:16:49
Epoch 3 | iter 3970 step 3970 | loss train: 4.778, val: 5.588 | iter time: 142.05 ms (step) remaining time: 0:16:46
Epoch 3 | iter 3980 step 3980 | loss train: 4.748, val: 5.588 | iter time: 142.03 ms (step) remaining time: 0:16:43
Epoch 3 | iter 3990 step 3990 | loss train: 4.768, val: 5.588 | iter time: 141.51 ms (step) remaining time: 0:16:41
Epoch 3 | iter 4000 step 4000 | loss train: 4.768, val: 5.588 | iter time: 141.81 ms (step) remaining time: 0:16:38
Validating ...
iter 4000: val loss 5.5827, val time: 4321.84 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00004000/lit_model.pth'
Epoch 3 | iter 4010 step 4010 | loss train: 4.781, val: 5.583 | iter time: 141.34 ms (step) remaining time: 0:16:53
Epoch 3 | iter 4020 step 4020 | loss train: 4.762, val: 5.583 | iter time: 140.94 ms (step) remaining time: 0:16:50
Epoch 3 | iter 4030 step 4030 | loss train: 4.785, val: 5.583 | iter time: 140.90 ms (step) remaining time: 0:16:47
Epoch 3 | iter 4040 step 4040 | loss train: 4.767, val: 5.583 | iter time: 142.07 ms (step) remaining time: 0:16:45
Epoch 3 | iter 4050 step 4050 | loss train: 4.789, val: 5.583 | iter time: 141.92 ms (step) remaining time: 0:16:42
Epoch 3 | iter 4060 step 4060 | loss train: 4.773, val: 5.583 | iter time: 141.06 ms (step) remaining time: 0:16:39
Epoch 3 | iter 4070 step 4070 | loss train: 4.769, val: 5.583 | iter time: 142.20 ms (step) remaining time: 0:16:37
Epoch 3 | iter 4080 step 4080 | loss train: 4.814, val: 5.583 | iter time: 142.16 ms (step) remaining time: 0:16:34
Epoch 3 | iter 4090 step 4090 | loss train: 4.818, val: 5.583 | iter time: 141.77 ms (step) remaining time: 0:16:31
Epoch 3 | iter 4100 step 4100 | loss train: 4.777, val: 5.583 | iter time: 141.60 ms (step) remaining time: 0:16:29
Validating ...
iter 4100: val loss 5.5836, val time: 4284.77 ms
Epoch 3 | iter 4110 step 4110 | loss train: 4.750, val: 5.584 | iter time: 141.22 ms (step) remaining time: 0:16:31
Epoch 3 | iter 4120 step 4120 | loss train: 4.806, val: 5.584 | iter time: 141.87 ms (step) remaining time: 0:16:29
Epoch 3 | iter 4130 step 4130 | loss train: 4.774, val: 5.584 | iter time: 142.85 ms (step) remaining time: 0:16:26
Epoch 3 | iter 4140 step 4140 | loss train: 4.772, val: 5.584 | iter time: 141.31 ms (step) remaining time: 0:16:23
Epoch 3 | iter 4150 step 4150 | loss train: 4.754, val: 5.584 | iter time: 141.93 ms (step) remaining time: 0:16:21
Epoch 3 | iter 4160 step 4160 | loss train: 4.771, val: 5.584 | iter time: 142.18 ms (step) remaining time: 0:16:18
Epoch 3 | iter 4170 step 4170 | loss train: 4.775, val: 5.584 | iter time: 141.74 ms (step) remaining time: 0:16:16
Epoch 3 | iter 4180 step 4180 | loss train: 4.776, val: 5.584 | iter time: 141.68 ms (step) remaining time: 0:16:13
Epoch 3 | iter 4190 step 4190 | loss train: 4.807, val: 5.584 | iter time: 142.41 ms (step) remaining time: 0:16:10
Epoch 3 | iter 4200 step 4200 | loss train: 4.708, val: 5.584 | iter time: 141.48 ms (step) remaining time: 0:16:08
Validating ...
iter 4200: val loss 5.5839, val time: 4288.45 ms
Epoch 3 | iter 4210 step 4210 | loss train: 4.783, val: 5.584 | iter time: 142.46 ms (step) remaining time: 0:16:10
Epoch 3 | iter 4220 step 4220 | loss train: 4.735, val: 5.584 | iter time: 141.91 ms (step) remaining time: 0:16:08
Epoch 3 | iter 4230 step 4230 | loss train: 4.810, val: 5.584 | iter time: 140.85 ms (step) remaining time: 0:16:05
Epoch 3 | iter 4240 step 4240 | loss train: 4.819, val: 5.584 | iter time: 142.87 ms (step) remaining time: 0:16:02
Epoch 3 | iter 4250 step 4250 | loss train: 4.769, val: 5.584 | iter time: 142.32 ms (step) remaining time: 0:16:00
Epoch 3 | iter 4260 step 4260 | loss train: 4.782, val: 5.584 | iter time: 141.67 ms (step) remaining time: 0:15:57
Epoch 3 | iter 4270 step 4270 | loss train: 4.806, val: 5.584 | iter time: 141.96 ms (step) remaining time: 0:15:55
Epoch 3 | iter 4280 step 4280 | loss train: 4.749, val: 5.584 | iter time: 142.73 ms (step) remaining time: 0:15:52
Epoch 3 | iter 4290 step 4290 | loss train: 4.807, val: 5.584 | iter time: 142.22 ms (step) remaining time: 0:15:50
Epoch 3 | iter 4300 step 4300 | loss train: 4.738, val: 5.584 | iter time: 142.59 ms (step) remaining time: 0:15:47
Validating ...
iter 4300: val loss 5.5803, val time: 4301.56 ms
Epoch 3 | iter 4310 step 4310 | loss train: 4.814, val: 5.580 | iter time: 141.45 ms (step) remaining time: 0:15:49
Epoch 3 | iter 4320 step 4320 | loss train: 4.758, val: 5.580 | iter time: 141.95 ms (step) remaining time: 0:15:47
Epoch 3 | iter 4330 step 4330 | loss train: 4.793, val: 5.580 | iter time: 141.80 ms (step) remaining time: 0:15:44
Epoch 3 | iter 4340 step 4340 | loss train: 4.759, val: 5.580 | iter time: 142.11 ms (step) remaining time: 0:15:42
Epoch 3 | iter 4350 step 4350 | loss train: 4.771, val: 5.580 | iter time: 142.20 ms (step) remaining time: 0:15:39
Epoch 3 | iter 4360 step 4360 | loss train: 4.778, val: 5.580 | iter time: 142.86 ms (step) remaining time: 0:15:36
Epoch 3 | iter 4370 step 4370 | loss train: 4.792, val: 5.580 | iter time: 141.75 ms (step) remaining time: 0:15:34
Epoch 3 | iter 4380 step 4380 | loss train: 4.757, val: 5.580 | iter time: 142.07 ms (step) remaining time: 0:15:31
Epoch 3 | iter 4390 step 4390 | loss train: 4.767, val: 5.580 | iter time: 142.29 ms (step) remaining time: 0:15:29
Epoch 3 | iter 4400 step 4400 | loss train: 4.801, val: 5.580 | iter time: 142.38 ms (step) remaining time: 0:15:26
Validating ...
iter 4400: val loss 5.5769, val time: 4316.79 ms
Epoch 3 | iter 4410 step 4410 | loss train: 4.764, val: 5.577 | iter time: 142.54 ms (step) remaining time: 0:15:28
Epoch 3 | iter 4420 step 4420 | loss train: 4.781, val: 5.577 | iter time: 142.74 ms (step) remaining time: 0:15:26
Epoch 3 | iter 4430 step 4430 | loss train: 4.788, val: 5.577 | iter time: 141.84 ms (step) remaining time: 0:15:23
Epoch 3 | iter 4440 step 4440 | loss train: 4.817, val: 5.577 | iter time: 142.30 ms (step) remaining time: 0:15:21
Epoch 3 | iter 4450 step 4450 | loss train: 4.782, val: 5.577 | iter time: 142.24 ms (step) remaining time: 0:15:18
Epoch 3 | iter 4460 step 4460 | loss train: 4.756, val: 5.577 | iter time: 143.09 ms (step) remaining time: 0:15:16
Epoch 3 | iter 4470 step 4470 | loss train: 4.791, val: 5.577 | iter time: 143.61 ms (step) remaining time: 0:15:13
Epoch 3 | iter 4480 step 4480 | loss train: 4.805, val: 5.577 | iter time: 142.61 ms (step) remaining time: 0:15:11
Epoch 3 | iter 4490 step 4490 | loss train: 4.802, val: 5.577 | iter time: 143.56 ms (step) remaining time: 0:15:08
Epoch 3 | iter 4500 step 4500 | loss train: 4.782, val: 5.577 | iter time: 142.77 ms (step) remaining time: 0:15:06
Validating ...
iter 4500: val loss 5.5702, val time: 4316.00 ms
Epoch 3 | iter 4510 step 4510 | loss train: 4.773, val: 5.570 | iter time: 143.57 ms (step) remaining time: 0:15:08
Epoch 3 | iter 4520 step 4520 | loss train: 4.774, val: 5.570 | iter time: 143.59 ms (step) remaining time: 0:15:05
Epoch 3 | iter 4530 step 4530 | loss train: 4.821, val: 5.570 | iter time: 143.34 ms (step) remaining time: 0:15:03
Epoch 3 | iter 4540 step 4540 | loss train: 4.795, val: 5.570 | iter time: 141.66 ms (step) remaining time: 0:15:00
Epoch 3 | iter 4550 step 4550 | loss train: 4.777, val: 5.570 | iter time: 141.85 ms (step) remaining time: 0:14:58
Epoch 3 | iter 4560 step 4560 | loss train: 4.807, val: 5.570 | iter time: 142.11 ms (step) remaining time: 0:14:55
Epoch 3 | iter 4570 step 4570 | loss train: 4.779, val: 5.570 | iter time: 141.69 ms (step) remaining time: 0:14:53
Epoch 3 | iter 4580 step 4580 | loss train: 4.788, val: 5.570 | iter time: 142.49 ms (step) remaining time: 0:14:50
Epoch 3 | iter 4590 step 4590 | loss train: 4.768, val: 5.570 | iter time: 142.95 ms (step) remaining time: 0:14:48
Epoch 3 | iter 4600 step 4600 | loss train: 4.820, val: 5.570 | iter time: 142.12 ms (step) remaining time: 0:14:45
Validating ...
iter 4600: val loss 5.5789, val time: 4304.43 ms
Epoch 3 | iter 4610 step 4610 | loss train: 4.793, val: 5.579 | iter time: 142.74 ms (step) remaining time: 0:14:47
Epoch 3 | iter 4620 step 4620 | loss train: 4.776, val: 5.579 | iter time: 142.39 ms (step) remaining time: 0:14:45
Epoch 3 | iter 4630 step 4630 | loss train: 4.783, val: 5.579 | iter time: 141.80 ms (step) remaining time: 0:14:42
Epoch 3 | iter 4640 step 4640 | loss train: 4.823, val: 5.579 | iter time: 142.55 ms (step) remaining time: 0:14:40
Epoch 3 | iter 4650 step 4650 | loss train: 4.773, val: 5.579 | iter time: 141.74 ms (step) remaining time: 0:14:37
Epoch 3 | iter 4660 step 4660 | loss train: 4.777, val: 5.579 | iter time: 143.15 ms (step) remaining time: 0:14:35
Epoch 3 | iter 4670 step 4670 | loss train: 4.782, val: 5.579 | iter time: 142.86 ms (step) remaining time: 0:14:32
Epoch 3 | iter 4680 step 4680 | loss train: 4.811, val: 5.579 | iter time: 142.31 ms (step) remaining time: 0:14:30
Epoch 3 | iter 4690 step 4690 | loss train: 4.782, val: 5.579 | iter time: 142.31 ms (step) remaining time: 0:14:27
Epoch 3 | iter 4700 step 4700 | loss train: 4.807, val: 5.579 | iter time: 143.44 ms (step) remaining time: 0:14:25
Validating ...
iter 4700: val loss 5.5742, val time: 4318.41 ms
Epoch 3 | iter 4710 step 4710 | loss train: 4.790, val: 5.574 | iter time: 141.52 ms (step) remaining time: 0:14:26
Epoch 3 | iter 4720 step 4720 | loss train: 4.784, val: 5.574 | iter time: 141.67 ms (step) remaining time: 0:14:24
Epoch 3 | iter 4730 step 4730 | loss train: 4.806, val: 5.574 | iter time: 142.44 ms (step) remaining time: 0:14:22
Epoch 3 | iter 4740 step 4740 | loss train: 4.807, val: 5.574 | iter time: 141.86 ms (step) remaining time: 0:14:19
Epoch 3 | iter 4750 step 4750 | loss train: 4.803, val: 5.574 | iter time: 141.40 ms (step) remaining time: 0:14:17
Epoch 3 | iter 4760 step 4760 | loss train: 4.780, val: 5.574 | iter time: 142.93 ms (step) remaining time: 0:14:14
Epoch 3 | iter 4770 step 4770 | loss train: 4.774, val: 5.574 | iter time: 142.16 ms (step) remaining time: 0:14:12
Epoch 3 | iter 4780 step 4780 | loss train: 4.773, val: 5.574 | iter time: 141.95 ms (step) remaining time: 0:14:09
Epoch 4 | iter 4790 step 4790 | loss train: 4.758, val: 5.574 | iter time: 141.82 ms (step) remaining time: 0:14:07
Epoch 4 | iter 4800 step 4800 | loss train: 4.747, val: 5.574 | iter time: 142.57 ms (step) remaining time: 0:14:05
Validating ...
iter 4800: val loss 5.5756, val time: 4298.20 ms
Epoch 4 | iter 4810 step 4810 | loss train: 4.790, val: 5.576 | iter time: 141.63 ms (step) remaining time: 0:14:06
Epoch 4 | iter 4820 step 4820 | loss train: 4.743, val: 5.576 | iter time: 142.20 ms (step) remaining time: 0:14:04
Epoch 4 | iter 4830 step 4830 | loss train: 4.718, val: 5.576 | iter time: 142.87 ms (step) remaining time: 0:14:02
Epoch 4 | iter 4840 step 4840 | loss train: 4.740, val: 5.576 | iter time: 142.78 ms (step) remaining time: 0:13:59
Epoch 4 | iter 4850 step 4850 | loss train: 4.751, val: 5.576 | iter time: 141.80 ms (step) remaining time: 0:13:57
Epoch 4 | iter 4860 step 4860 | loss train: 4.756, val: 5.576 | iter time: 142.10 ms (step) remaining time: 0:13:54
Epoch 4 | iter 4870 step 4870 | loss train: 4.736, val: 5.576 | iter time: 142.95 ms (step) remaining time: 0:13:52
Epoch 4 | iter 4880 step 4880 | loss train: 4.701, val: 5.576 | iter time: 142.67 ms (step) remaining time: 0:13:49
Epoch 4 | iter 4890 step 4890 | loss train: 4.740, val: 5.576 | iter time: 142.61 ms (step) remaining time: 0:13:47
Epoch 4 | iter 4900 step 4900 | loss train: 4.731, val: 5.576 | iter time: 141.65 ms (step) remaining time: 0:13:45
Validating ...
iter 4900: val loss 5.5778, val time: 4315.10 ms
Epoch 4 | iter 4910 step 4910 | loss train: 4.724, val: 5.578 | iter time: 143.35 ms (step) remaining time: 0:13:46
Epoch 4 | iter 4920 step 4920 | loss train: 4.687, val: 5.578 | iter time: 143.20 ms (step) remaining time: 0:13:44
Epoch 4 | iter 4930 step 4930 | loss train: 4.718, val: 5.578 | iter time: 141.66 ms (step) remaining time: 0:13:41
Epoch 4 | iter 4940 step 4940 | loss train: 4.735, val: 5.578 | iter time: 143.06 ms (step) remaining time: 0:13:39
Epoch 4 | iter 4950 step 4950 | loss train: 4.699, val: 5.578 | iter time: 142.55 ms (step) remaining time: 0:13:36
Epoch 4 | iter 4960 step 4960 | loss train: 4.765, val: 5.578 | iter time: 142.39 ms (step) remaining time: 0:13:34
Epoch 4 | iter 4970 step 4970 | loss train: 4.753, val: 5.578 | iter time: 141.42 ms (step) remaining time: 0:13:32
Epoch 4 | iter 4980 step 4980 | loss train: 4.747, val: 5.578 | iter time: 142.67 ms (step) remaining time: 0:13:29
Epoch 4 | iter 4990 step 4990 | loss train: 4.727, val: 5.578 | iter time: 141.30 ms (step) remaining time: 0:13:27
Epoch 4 | iter 5000 step 5000 | loss train: 4.756, val: 5.578 | iter time: 142.03 ms (step) remaining time: 0:13:24
Validating ...
iter 5000: val loss 5.5822, val time: 4304.89 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00005000/lit_model.pth'
Epoch 4 | iter 5010 step 5010 | loss train: 4.719, val: 5.582 | iter time: 141.50 ms (step) remaining time: 0:13:34
Epoch 4 | iter 5020 step 5020 | loss train: 4.744, val: 5.582 | iter time: 141.93 ms (step) remaining time: 0:13:31
Epoch 4 | iter 5030 step 5030 | loss train: 4.723, val: 5.582 | iter time: 141.04 ms (step) remaining time: 0:13:29
Epoch 4 | iter 5040 step 5040 | loss train: 4.710, val: 5.582 | iter time: 141.93 ms (step) remaining time: 0:13:26
Epoch 4 | iter 5050 step 5050 | loss train: 4.771, val: 5.582 | iter time: 141.80 ms (step) remaining time: 0:13:24
Epoch 4 | iter 5060 step 5060 | loss train: 4.751, val: 5.582 | iter time: 141.68 ms (step) remaining time: 0:13:22
Epoch 4 | iter 5070 step 5070 | loss train: 4.784, val: 5.582 | iter time: 141.93 ms (step) remaining time: 0:13:19
Epoch 4 | iter 5080 step 5080 | loss train: 4.743, val: 5.582 | iter time: 141.54 ms (step) remaining time: 0:13:17
Epoch 4 | iter 5090 step 5090 | loss train: 4.692, val: 5.582 | iter time: 141.23 ms (step) remaining time: 0:13:14
Epoch 4 | iter 5100 step 5100 | loss train: 4.763, val: 5.582 | iter time: 141.84 ms (step) remaining time: 0:13:12
Validating ...
iter 5100: val loss 5.5803, val time: 4292.63 ms
Epoch 4 | iter 5110 step 5110 | loss train: 4.676, val: 5.580 | iter time: 142.53 ms (step) remaining time: 0:13:13
Epoch 4 | iter 5120 step 5120 | loss train: 4.756, val: 5.580 | iter time: 140.86 ms (step) remaining time: 0:13:11
Epoch 4 | iter 5130 step 5130 | loss train: 4.752, val: 5.580 | iter time: 141.99 ms (step) remaining time: 0:13:08
Epoch 4 | iter 5140 step 5140 | loss train: 4.772, val: 5.580 | iter time: 140.84 ms (step) remaining time: 0:13:06
Epoch 4 | iter 5150 step 5150 | loss train: 4.740, val: 5.580 | iter time: 141.35 ms (step) remaining time: 0:13:03
Epoch 4 | iter 5160 step 5160 | loss train: 4.784, val: 5.580 | iter time: 140.92 ms (step) remaining time: 0:13:01
Epoch 4 | iter 5170 step 5170 | loss train: 4.780, val: 5.580 | iter time: 142.46 ms (step) remaining time: 0:12:59
Epoch 4 | iter 5180 step 5180 | loss train: 4.751, val: 5.580 | iter time: 142.27 ms (step) remaining time: 0:12:56
Epoch 4 | iter 5190 step 5190 | loss train: 4.732, val: 5.580 | iter time: 141.36 ms (step) remaining time: 0:12:54
Epoch 4 | iter 5200 step 5200 | loss train: 4.733, val: 5.580 | iter time: 141.47 ms (step) remaining time: 0:12:51
Validating ...
iter 5200: val loss 5.5795, val time: 4307.53 ms
Epoch 4 | iter 5210 step 5210 | loss train: 4.757, val: 5.580 | iter time: 141.73 ms (step) remaining time: 0:12:52
Epoch 4 | iter 5220 step 5220 | loss train: 4.755, val: 5.580 | iter time: 140.98 ms (step) remaining time: 0:12:50
Epoch 4 | iter 5230 step 5230 | loss train: 4.718, val: 5.580 | iter time: 141.66 ms (step) remaining time: 0:12:48
Epoch 4 | iter 5240 step 5240 | loss train: 4.756, val: 5.580 | iter time: 142.46 ms (step) remaining time: 0:12:45
Epoch 4 | iter 5250 step 5250 | loss train: 4.730, val: 5.580 | iter time: 141.61 ms (step) remaining time: 0:12:43
Epoch 4 | iter 5260 step 5260 | loss train: 4.741, val: 5.580 | iter time: 141.71 ms (step) remaining time: 0:12:41
Epoch 4 | iter 5270 step 5270 | loss train: 4.785, val: 5.580 | iter time: 141.70 ms (step) remaining time: 0:12:38
Epoch 4 | iter 5280 step 5280 | loss train: 4.726, val: 5.580 | iter time: 142.38 ms (step) remaining time: 0:12:36
Epoch 4 | iter 5290 step 5290 | loss train: 4.737, val: 5.580 | iter time: 141.59 ms (step) remaining time: 0:12:33
Epoch 4 | iter 5300 step 5300 | loss train: 4.724, val: 5.580 | iter time: 142.71 ms (step) remaining time: 0:12:31
Validating ...
iter 5300: val loss 5.5842, val time: 4305.32 ms
Epoch 4 | iter 5310 step 5310 | loss train: 4.708, val: 5.584 | iter time: 142.04 ms (step) remaining time: 0:12:32
Epoch 4 | iter 5320 step 5320 | loss train: 4.736, val: 5.584 | iter time: 143.50 ms (step) remaining time: 0:12:30
Epoch 4 | iter 5330 step 5330 | loss train: 4.731, val: 5.584 | iter time: 142.10 ms (step) remaining time: 0:12:27
Epoch 4 | iter 5340 step 5340 | loss train: 4.777, val: 5.584 | iter time: 142.75 ms (step) remaining time: 0:12:25
Epoch 4 | iter 5350 step 5350 | loss train: 4.717, val: 5.584 | iter time: 142.95 ms (step) remaining time: 0:12:23
Epoch 4 | iter 5360 step 5360 | loss train: 4.762, val: 5.584 | iter time: 140.99 ms (step) remaining time: 0:12:20
Epoch 4 | iter 5370 step 5370 | loss train: 4.757, val: 5.584 | iter time: 142.19 ms (step) remaining time: 0:12:18
Epoch 4 | iter 5380 step 5380 | loss train: 4.719, val: 5.584 | iter time: 141.05 ms (step) remaining time: 0:12:16
Epoch 4 | iter 5390 step 5390 | loss train: 4.750, val: 5.584 | iter time: 142.22 ms (step) remaining time: 0:12:13
Epoch 4 | iter 5400 step 5400 | loss train: 4.739, val: 5.584 | iter time: 142.36 ms (step) remaining time: 0:12:11
Validating ...
iter 5400: val loss 5.5864, val time: 4292.39 ms
Epoch 4 | iter 5410 step 5410 | loss train: 4.753, val: 5.586 | iter time: 142.95 ms (step) remaining time: 0:12:12
Epoch 4 | iter 5420 step 5420 | loss train: 4.731, val: 5.586 | iter time: 141.15 ms (step) remaining time: 0:12:09
Epoch 4 | iter 5430 step 5430 | loss train: 4.728, val: 5.586 | iter time: 142.34 ms (step) remaining time: 0:12:07
Epoch 4 | iter 5440 step 5440 | loss train: 4.700, val: 5.586 | iter time: 142.12 ms (step) remaining time: 0:12:05
Epoch 4 | iter 5450 step 5450 | loss train: 4.728, val: 5.586 | iter time: 142.46 ms (step) remaining time: 0:12:02
Epoch 4 | iter 5460 step 5460 | loss train: 4.766, val: 5.586 | iter time: 142.08 ms (step) remaining time: 0:12:00
Epoch 4 | iter 5470 step 5470 | loss train: 4.721, val: 5.586 | iter time: 142.04 ms (step) remaining time: 0:11:58
Epoch 4 | iter 5480 step 5480 | loss train: 4.771, val: 5.586 | iter time: 141.56 ms (step) remaining time: 0:11:55
Epoch 4 | iter 5490 step 5490 | loss train: 4.715, val: 5.586 | iter time: 142.44 ms (step) remaining time: 0:11:53
Epoch 4 | iter 5500 step 5500 | loss train: 4.744, val: 5.586 | iter time: 142.01 ms (step) remaining time: 0:11:51
Validating ...
iter 5500: val loss 5.5781, val time: 4309.79 ms
Epoch 4 | iter 5510 step 5510 | loss train: 4.749, val: 5.578 | iter time: 141.26 ms (step) remaining time: 0:11:51
Epoch 4 | iter 5520 step 5520 | loss train: 4.766, val: 5.578 | iter time: 143.52 ms (step) remaining time: 0:11:49
Epoch 4 | iter 5530 step 5530 | loss train: 4.734, val: 5.578 | iter time: 142.71 ms (step) remaining time: 0:11:47
Epoch 4 | iter 5540 step 5540 | loss train: 4.733, val: 5.578 | iter time: 142.22 ms (step) remaining time: 0:11:44
Epoch 4 | iter 5550 step 5550 | loss train: 4.702, val: 5.578 | iter time: 141.90 ms (step) remaining time: 0:11:42
Epoch 4 | iter 5560 step 5560 | loss train: 4.759, val: 5.578 | iter time: 142.41 ms (step) remaining time: 0:11:40
Epoch 4 | iter 5570 step 5570 | loss train: 4.778, val: 5.578 | iter time: 142.76 ms (step) remaining time: 0:11:37
Epoch 4 | iter 5580 step 5580 | loss train: 4.762, val: 5.578 | iter time: 142.01 ms (step) remaining time: 0:11:35
Epoch 4 | iter 5590 step 5590 | loss train: 4.750, val: 5.578 | iter time: 141.51 ms (step) remaining time: 0:11:33
Epoch 4 | iter 5600 step 5600 | loss train: 4.773, val: 5.578 | iter time: 142.25 ms (step) remaining time: 0:11:31
Validating ...
iter 5600: val loss 5.5822, val time: 4318.03 ms
Epoch 4 | iter 5610 step 5610 | loss train: 4.785, val: 5.582 | iter time: 143.22 ms (step) remaining time: 0:11:31
Epoch 4 | iter 5620 step 5620 | loss train: 4.701, val: 5.582 | iter time: 142.72 ms (step) remaining time: 0:11:29
Epoch 4 | iter 5630 step 5630 | loss train: 4.725, val: 5.582 | iter time: 142.56 ms (step) remaining time: 0:11:26
Epoch 4 | iter 5640 step 5640 | loss train: 4.701, val: 5.582 | iter time: 142.66 ms (step) remaining time: 0:11:24
Epoch 4 | iter 5650 step 5650 | loss train: 4.737, val: 5.582 | iter time: 142.24 ms (step) remaining time: 0:11:22
Epoch 4 | iter 5660 step 5660 | loss train: 4.786, val: 5.582 | iter time: 142.03 ms (step) remaining time: 0:11:20
Epoch 4 | iter 5670 step 5670 | loss train: 4.729, val: 5.582 | iter time: 142.91 ms (step) remaining time: 0:11:17
Epoch 4 | iter 5680 step 5680 | loss train: 4.801, val: 5.582 | iter time: 142.70 ms (step) remaining time: 0:11:15
Epoch 4 | iter 5690 step 5690 | loss train: 4.755, val: 5.582 | iter time: 142.87 ms (step) remaining time: 0:11:13
Epoch 4 | iter 5700 step 5700 | loss train: 4.714, val: 5.582 | iter time: 142.07 ms (step) remaining time: 0:11:11
Validating ...
iter 5700: val loss 5.5800, val time: 4322.68 ms
Epoch 4 | iter 5710 step 5710 | loss train: 4.803, val: 5.580 | iter time: 142.19 ms (step) remaining time: 0:11:11
Epoch 4 | iter 5720 step 5720 | loss train: 4.731, val: 5.580 | iter time: 142.23 ms (step) remaining time: 0:11:09
Epoch 4 | iter 5730 step 5730 | loss train: 4.763, val: 5.580 | iter time: 141.76 ms (step) remaining time: 0:11:06
Epoch 4 | iter 5740 step 5740 | loss train: 4.748, val: 5.580 | iter time: 142.26 ms (step) remaining time: 0:11:04
Epoch 4 | iter 5750 step 5750 | loss train: 4.740, val: 5.580 | iter time: 142.63 ms (step) remaining time: 0:11:02
Epoch 4 | iter 5760 step 5760 | loss train: 4.715, val: 5.580 | iter time: 141.26 ms (step) remaining time: 0:11:00
Epoch 4 | iter 5770 step 5770 | loss train: 4.713, val: 5.580 | iter time: 143.04 ms (step) remaining time: 0:10:57
Epoch 4 | iter 5780 step 5780 | loss train: 4.717, val: 5.580 | iter time: 142.69 ms (step) remaining time: 0:10:55
Epoch 4 | iter 5790 step 5790 | loss train: 4.709, val: 5.580 | iter time: 141.49 ms (step) remaining time: 0:10:53
Epoch 4 | iter 5800 step 5800 | loss train: 4.734, val: 5.580 | iter time: 142.18 ms (step) remaining time: 0:10:51
Validating ...
iter 5800: val loss 5.5750, val time: 4328.08 ms
Epoch 4 | iter 5810 step 5810 | loss train: 4.763, val: 5.575 | iter time: 142.68 ms (step) remaining time: 0:10:51
Epoch 4 | iter 5820 step 5820 | loss train: 4.753, val: 5.575 | iter time: 142.82 ms (step) remaining time: 0:10:49
Epoch 4 | iter 5830 step 5830 | loss train: 4.750, val: 5.575 | iter time: 142.41 ms (step) remaining time: 0:10:46
Epoch 4 | iter 5840 step 5840 | loss train: 4.759, val: 5.575 | iter time: 141.84 ms (step) remaining time: 0:10:44
Epoch 4 | iter 5850 step 5850 | loss train: 4.753, val: 5.575 | iter time: 142.61 ms (step) remaining time: 0:10:42
Epoch 4 | iter 5860 step 5860 | loss train: 4.713, val: 5.575 | iter time: 143.37 ms (step) remaining time: 0:10:40
Epoch 4 | iter 5870 step 5870 | loss train: 4.740, val: 5.575 | iter time: 141.30 ms (step) remaining time: 0:10:37
Epoch 4 | iter 5880 step 5880 | loss train: 4.720, val: 5.575 | iter time: 141.88 ms (step) remaining time: 0:10:35
Epoch 4 | iter 5890 step 5890 | loss train: 4.773, val: 5.575 | iter time: 142.93 ms (step) remaining time: 0:10:33
Epoch 4 | iter 5900 step 5900 | loss train: 4.770, val: 5.575 | iter time: 143.23 ms (step) remaining time: 0:10:31
Validating ...
iter 5900: val loss 5.5741, val time: 4331.54 ms
Epoch 4 | iter 5910 step 5910 | loss train: 4.742, val: 5.574 | iter time: 142.78 ms (step) remaining time: 0:10:31
Epoch 4 | iter 5920 step 5920 | loss train: 4.766, val: 5.574 | iter time: 142.36 ms (step) remaining time: 0:10:29
Epoch 4 | iter 5930 step 5930 | loss train: 4.770, val: 5.574 | iter time: 142.04 ms (step) remaining time: 0:10:26
Epoch 4 | iter 5940 step 5940 | loss train: 4.763, val: 5.574 | iter time: 143.04 ms (step) remaining time: 0:10:24
Epoch 4 | iter 5950 step 5950 | loss train: 4.731, val: 5.574 | iter time: 142.12 ms (step) remaining time: 0:10:22
Epoch 4 | iter 5960 step 5960 | loss train: 4.776, val: 5.574 | iter time: 143.32 ms (step) remaining time: 0:10:20
Epoch 4 | iter 5970 step 5970 | loss train: 4.685, val: 5.574 | iter time: 143.43 ms (step) remaining time: 0:10:18
Epoch 4 | iter 5980 step 5980 | loss train: 4.745, val: 5.574 | iter time: 142.25 ms (step) remaining time: 0:10:15
Epoch 4 | iter 5990 step 5990 | loss train: 4.767, val: 5.574 | iter time: 142.49 ms (step) remaining time: 0:10:13
Epoch 4 | iter 6000 step 6000 | loss train: 4.760, val: 5.574 | iter time: 142.83 ms (step) remaining time: 0:10:11
Validating ...
iter 6000: val loss 5.5705, val time: 4312.64 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00006000/lit_model.pth'
Epoch 4 | iter 6010 step 6010 | loss train: 4.767, val: 5.570 | iter time: 141.42 ms (step) remaining time: 0:10:16
Epoch 4 | iter 6020 step 6020 | loss train: 4.794, val: 5.570 | iter time: 141.76 ms (step) remaining time: 0:10:13
Epoch 4 | iter 6030 step 6030 | loss train: 4.785, val: 5.570 | iter time: 141.14 ms (step) remaining time: 0:10:11
Epoch 4 | iter 6040 step 6040 | loss train: 4.776, val: 5.570 | iter time: 141.08 ms (step) remaining time: 0:10:09
Epoch 4 | iter 6050 step 6050 | loss train: 4.699, val: 5.570 | iter time: 141.47 ms (step) remaining time: 0:10:07
Epoch 4 | iter 6060 step 6060 | loss train: 4.773, val: 5.570 | iter time: 141.84 ms (step) remaining time: 0:10:04
Epoch 4 | iter 6070 step 6070 | loss train: 4.774, val: 5.570 | iter time: 141.34 ms (step) remaining time: 0:10:02
Epoch 4 | iter 6080 step 6080 | loss train: 4.733, val: 5.570 | iter time: 141.92 ms (step) remaining time: 0:10:00
Epoch 4 | iter 6090 step 6090 | loss train: 4.723, val: 5.570 | iter time: 141.49 ms (step) remaining time: 0:09:58
Epoch 4 | iter 6100 step 6100 | loss train: 4.777, val: 5.570 | iter time: 140.86 ms (step) remaining time: 0:09:56
Validating ...
iter 6100: val loss 5.5695, val time: 4309.32 ms
Epoch 4 | iter 6110 step 6110 | loss train: 4.751, val: 5.570 | iter time: 142.54 ms (step) remaining time: 0:09:55
Epoch 4 | iter 6120 step 6120 | loss train: 4.717, val: 5.570 | iter time: 142.67 ms (step) remaining time: 0:09:53
Epoch 4 | iter 6130 step 6130 | loss train: 4.780, val: 5.570 | iter time: 141.91 ms (step) remaining time: 0:09:51
Epoch 4 | iter 6140 step 6140 | loss train: 4.762, val: 5.570 | iter time: 141.94 ms (step) remaining time: 0:09:49
Epoch 4 | iter 6150 step 6150 | loss train: 4.739, val: 5.570 | iter time: 141.38 ms (step) remaining time: 0:09:47
Epoch 4 | iter 6160 step 6160 | loss train: 4.710, val: 5.570 | iter time: 141.77 ms (step) remaining time: 0:09:44
Epoch 4 | iter 6170 step 6170 | loss train: 4.732, val: 5.570 | iter time: 142.10 ms (step) remaining time: 0:09:42
Epoch 4 | iter 6180 step 6180 | loss train: 4.735, val: 5.570 | iter time: 141.54 ms (step) remaining time: 0:09:40
Epoch 4 | iter 6190 step 6190 | loss train: 4.783, val: 5.570 | iter time: 142.04 ms (step) remaining time: 0:09:38
Epoch 4 | iter 6200 step 6200 | loss train: 4.722, val: 5.570 | iter time: 141.68 ms (step) remaining time: 0:09:35
Validating ...
iter 6200: val loss 5.5712, val time: 4315.59 ms
Epoch 4 | iter 6210 step 6210 | loss train: 4.716, val: 5.571 | iter time: 142.29 ms (step) remaining time: 0:09:35
Epoch 4 | iter 6220 step 6220 | loss train: 4.739, val: 5.571 | iter time: 142.89 ms (step) remaining time: 0:09:33
Epoch 4 | iter 6230 step 6230 | loss train: 4.729, val: 5.571 | iter time: 141.42 ms (step) remaining time: 0:09:31
Epoch 4 | iter 6240 step 6240 | loss train: 4.702, val: 5.571 | iter time: 141.80 ms (step) remaining time: 0:09:29
Epoch 4 | iter 6250 step 6250 | loss train: 4.735, val: 5.571 | iter time: 141.71 ms (step) remaining time: 0:09:27
Epoch 4 | iter 6260 step 6260 | loss train: 4.726, val: 5.571 | iter time: 143.57 ms (step) remaining time: 0:09:24
Epoch 4 | iter 6270 step 6270 | loss train: 4.729, val: 5.571 | iter time: 143.50 ms (step) remaining time: 0:09:22
Epoch 4 | iter 6280 step 6280 | loss train: 4.747, val: 5.571 | iter time: 142.40 ms (step) remaining time: 0:09:20
Epoch 4 | iter 6290 step 6290 | loss train: 4.762, val: 5.571 | iter time: 142.22 ms (step) remaining time: 0:09:18
Epoch 4 | iter 6300 step 6300 | loss train: 4.798, val: 5.571 | iter time: 141.74 ms (step) remaining time: 0:09:16
Validating ...
iter 6300: val loss 5.5720, val time: 4300.24 ms
Epoch 4 | iter 6310 step 6310 | loss train: 4.770, val: 5.572 | iter time: 141.75 ms (step) remaining time: 0:09:15
Epoch 4 | iter 6320 step 6320 | loss train: 4.767, val: 5.572 | iter time: 142.23 ms (step) remaining time: 0:09:13
Epoch 4 | iter 6330 step 6330 | loss train: 4.759, val: 5.572 | iter time: 142.55 ms (step) remaining time: 0:09:11
Epoch 4 | iter 6340 step 6340 | loss train: 4.772, val: 5.572 | iter time: 141.84 ms (step) remaining time: 0:09:09
Epoch 4 | iter 6350 step 6350 | loss train: 4.765, val: 5.572 | iter time: 143.17 ms (step) remaining time: 0:09:07
Epoch 4 | iter 6360 step 6360 | loss train: 4.754, val: 5.572 | iter time: 143.21 ms (step) remaining time: 0:09:04
Epoch 4 | iter 6370 step 6370 | loss train: 4.754, val: 5.572 | iter time: 142.60 ms (step) remaining time: 0:09:02
Epoch 4 | iter 6380 step 6380 | loss train: 4.755, val: 5.572 | iter time: 143.14 ms (step) remaining time: 0:09:00
Epoch 5 | iter 6390 step 6390 | loss train: 4.694, val: 5.572 | iter time: 141.54 ms (step) remaining time: 0:08:58
Epoch 5 | iter 6400 step 6400 | loss train: 4.698, val: 5.572 | iter time: 141.85 ms (step) remaining time: 0:08:56
Validating ...
iter 6400: val loss 5.5779, val time: 4344.20 ms
Epoch 5 | iter 6410 step 6410 | loss train: 4.706, val: 5.578 | iter time: 141.60 ms (step) remaining time: 0:08:55
Epoch 5 | iter 6420 step 6420 | loss train: 4.676, val: 5.578 | iter time: 140.81 ms (step) remaining time: 0:08:53
Epoch 5 | iter 6430 step 6430 | loss train: 4.693, val: 5.578 | iter time: 141.73 ms (step) remaining time: 0:08:51
Epoch 5 | iter 6440 step 6440 | loss train: 4.688, val: 5.578 | iter time: 142.10 ms (step) remaining time: 0:08:49
Epoch 5 | iter 6450 step 6450 | loss train: 4.685, val: 5.578 | iter time: 142.51 ms (step) remaining time: 0:08:47
Epoch 5 | iter 6460 step 6460 | loss train: 4.694, val: 5.578 | iter time: 142.70 ms (step) remaining time: 0:08:44
Epoch 5 | iter 6470 step 6470 | loss train: 4.698, val: 5.578 | iter time: 142.77 ms (step) remaining time: 0:08:42
Epoch 5 | iter 6480 step 6480 | loss train: 4.700, val: 5.578 | iter time: 141.61 ms (step) remaining time: 0:08:40
Epoch 5 | iter 6490 step 6490 | loss train: 4.685, val: 5.578 | iter time: 142.44 ms (step) remaining time: 0:08:38
Epoch 5 | iter 6500 step 6500 | loss train: 4.705, val: 5.578 | iter time: 142.63 ms (step) remaining time: 0:08:36
Validating ...
iter 6500: val loss 5.5881, val time: 4328.75 ms
Epoch 5 | iter 6510 step 6510 | loss train: 4.717, val: 5.588 | iter time: 141.61 ms (step) remaining time: 0:08:35
Epoch 5 | iter 6520 step 6520 | loss train: 4.705, val: 5.588 | iter time: 142.21 ms (step) remaining time: 0:08:33
Epoch 5 | iter 6530 step 6530 | loss train: 4.712, val: 5.588 | iter time: 143.45 ms (step) remaining time: 0:08:31
Epoch 5 | iter 6540 step 6540 | loss train: 4.707, val: 5.588 | iter time: 142.45 ms (step) remaining time: 0:08:29
Epoch 5 | iter 6550 step 6550 | loss train: 4.764, val: 5.588 | iter time: 142.85 ms (step) remaining time: 0:08:27
Epoch 5 | iter 6560 step 6560 | loss train: 4.691, val: 5.588 | iter time: 142.03 ms (step) remaining time: 0:08:25
Epoch 5 | iter 6570 step 6570 | loss train: 4.670, val: 5.588 | iter time: 142.69 ms (step) remaining time: 0:08:22
Epoch 5 | iter 6580 step 6580 | loss train: 4.721, val: 5.588 | iter time: 143.17 ms (step) remaining time: 0:08:20
Epoch 5 | iter 6590 step 6590 | loss train: 4.722, val: 5.588 | iter time: 142.30 ms (step) remaining time: 0:08:18
Epoch 5 | iter 6600 step 6600 | loss train: 4.719, val: 5.588 | iter time: 142.97 ms (step) remaining time: 0:08:16
Validating ...
iter 6600: val loss 5.5886, val time: 4347.29 ms
Epoch 5 | iter 6610 step 6610 | loss train: 4.706, val: 5.589 | iter time: 142.28 ms (step) remaining time: 0:08:16
Epoch 5 | iter 6620 step 6620 | loss train: 4.699, val: 5.589 | iter time: 141.52 ms (step) remaining time: 0:08:13
Epoch 5 | iter 6630 step 6630 | loss train: 4.670, val: 5.589 | iter time: 141.81 ms (step) remaining time: 0:08:11
Epoch 5 | iter 6640 step 6640 | loss train: 4.711, val: 5.589 | iter time: 141.57 ms (step) remaining time: 0:08:09
Epoch 5 | iter 6650 step 6650 | loss train: 4.661, val: 5.589 | iter time: 142.27 ms (step) remaining time: 0:08:07
Epoch 5 | iter 6660 step 6660 | loss train: 4.703, val: 5.589 | iter time: 141.72 ms (step) remaining time: 0:08:05
Epoch 5 | iter 6670 step 6670 | loss train: 4.699, val: 5.589 | iter time: 141.96 ms (step) remaining time: 0:08:03
Epoch 5 | iter 6680 step 6680 | loss train: 4.723, val: 5.589 | iter time: 143.14 ms (step) remaining time: 0:08:00
Epoch 5 | iter 6690 step 6690 | loss train: 4.680, val: 5.589 | iter time: 141.75 ms (step) remaining time: 0:07:58
Epoch 5 | iter 6700 step 6700 | loss train: 4.704, val: 5.589 | iter time: 142.10 ms (step) remaining time: 0:07:56
Validating ...
iter 6700: val loss 5.5903, val time: 4318.67 ms
Epoch 5 | iter 6710 step 6710 | loss train: 4.699, val: 5.590 | iter time: 142.91 ms (step) remaining time: 0:07:56
Epoch 5 | iter 6720 step 6720 | loss train: 4.669, val: 5.590 | iter time: 142.07 ms (step) remaining time: 0:07:53
Epoch 5 | iter 6730 step 6730 | loss train: 4.704, val: 5.590 | iter time: 141.78 ms (step) remaining time: 0:07:51
Epoch 5 | iter 6740 step 6740 | loss train: 4.689, val: 5.590 | iter time: 142.99 ms (step) remaining time: 0:07:49
Epoch 5 | iter 6750 step 6750 | loss train: 4.733, val: 5.590 | iter time: 141.33 ms (step) remaining time: 0:07:47
Epoch 5 | iter 6760 step 6760 | loss train: 4.684, val: 5.590 | iter time: 142.36 ms (step) remaining time: 0:07:45
Epoch 5 | iter 6770 step 6770 | loss train: 4.599, val: 5.590 | iter time: 142.39 ms (step) remaining time: 0:07:43
Epoch 5 | iter 6780 step 6780 | loss train: 4.714, val: 5.590 | iter time: 142.45 ms (step) remaining time: 0:07:41
Epoch 5 | iter 6790 step 6790 | loss train: 4.733, val: 5.590 | iter time: 143.02 ms (step) remaining time: 0:07:39
Epoch 5 | iter 6800 step 6800 | loss train: 4.710, val: 5.590 | iter time: 141.59 ms (step) remaining time: 0:07:36
Validating ...
iter 6800: val loss 5.5927, val time: 4313.93 ms
Epoch 5 | iter 6810 step 6810 | loss train: 4.678, val: 5.593 | iter time: 141.97 ms (step) remaining time: 0:07:36
Epoch 5 | iter 6820 step 6820 | loss train: 4.712, val: 5.593 | iter time: 141.29 ms (step) remaining time: 0:07:34
Epoch 5 | iter 6830 step 6830 | loss train: 4.645, val: 5.593 | iter time: 141.36 ms (step) remaining time: 0:07:32
Epoch 5 | iter 6840 step 6840 | loss train: 4.672, val: 5.593 | iter time: 142.51 ms (step) remaining time: 0:07:29
Epoch 5 | iter 6850 step 6850 | loss train: 4.677, val: 5.593 | iter time: 141.24 ms (step) remaining time: 0:07:27
Epoch 5 | iter 6860 step 6860 | loss train: 4.745, val: 5.593 | iter time: 141.67 ms (step) remaining time: 0:07:25
Epoch 5 | iter 6870 step 6870 | loss train: 4.737, val: 5.593 | iter time: 141.66 ms (step) remaining time: 0:07:23
Epoch 5 | iter 6880 step 6880 | loss train: 4.700, val: 5.593 | iter time: 141.99 ms (step) remaining time: 0:07:21
Epoch 5 | iter 6890 step 6890 | loss train: 4.738, val: 5.593 | iter time: 143.02 ms (step) remaining time: 0:07:19
Epoch 5 | iter 6900 step 6900 | loss train: 4.721, val: 5.593 | iter time: 141.82 ms (step) remaining time: 0:07:17
Validating ...
iter 6900: val loss 5.5903, val time: 4321.31 ms
Epoch 5 | iter 6910 step 6910 | loss train: 4.659, val: 5.590 | iter time: 141.71 ms (step) remaining time: 0:07:16
Epoch 5 | iter 6920 step 6920 | loss train: 4.696, val: 5.590 | iter time: 142.17 ms (step) remaining time: 0:07:14
Epoch 5 | iter 6930 step 6930 | loss train: 4.696, val: 5.590 | iter time: 141.43 ms (step) remaining time: 0:07:12
Epoch 5 | iter 6940 step 6940 | loss train: 4.690, val: 5.590 | iter time: 142.37 ms (step) remaining time: 0:07:10
Epoch 5 | iter 6950 step 6950 | loss train: 4.694, val: 5.590 | iter time: 142.57 ms (step) remaining time: 0:07:08
Epoch 5 | iter 6960 step 6960 | loss train: 4.690, val: 5.590 | iter time: 141.94 ms (step) remaining time: 0:07:06
Epoch 5 | iter 6970 step 6970 | loss train: 4.711, val: 5.590 | iter time: 141.68 ms (step) remaining time: 0:07:03
Epoch 5 | iter 6980 step 6980 | loss train: 4.695, val: 5.590 | iter time: 141.32 ms (step) remaining time: 0:07:01
Epoch 5 | iter 6990 step 6990 | loss train: 4.731, val: 5.590 | iter time: 142.40 ms (step) remaining time: 0:06:59
Epoch 5 | iter 7000 step 7000 | loss train: 4.665, val: 5.590 | iter time: 142.48 ms (step) remaining time: 0:06:57
Validating ...
iter 7000: val loss 5.5888, val time: 4290.82 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00007000/lit_model.pth'
Epoch 5 | iter 7010 step 7010 | loss train: 4.675, val: 5.589 | iter time: 142.23 ms (step) remaining time: 0:06:59
Epoch 5 | iter 7020 step 7020 | loss train: 4.679, val: 5.589 | iter time: 142.34 ms (step) remaining time: 0:06:57
Epoch 5 | iter 7030 step 7030 | loss train: 4.689, val: 5.589 | iter time: 142.15 ms (step) remaining time: 0:06:55
Epoch 5 | iter 7040 step 7040 | loss train: 4.675, val: 5.589 | iter time: 141.94 ms (step) remaining time: 0:06:53
Epoch 5 | iter 7050 step 7050 | loss train: 4.718, val: 5.589 | iter time: 142.55 ms (step) remaining time: 0:06:51
Epoch 5 | iter 7060 step 7060 | loss train: 4.716, val: 5.589 | iter time: 142.12 ms (step) remaining time: 0:06:49
Epoch 5 | iter 7070 step 7070 | loss train: 4.720, val: 5.589 | iter time: 141.62 ms (step) remaining time: 0:06:47
Epoch 5 | iter 7080 step 7080 | loss train: 4.715, val: 5.589 | iter time: 141.40 ms (step) remaining time: 0:06:44
Epoch 5 | iter 7090 step 7090 | loss train: 4.727, val: 5.589 | iter time: 141.04 ms (step) remaining time: 0:06:42
Epoch 5 | iter 7100 step 7100 | loss train: 4.688, val: 5.589 | iter time: 140.99 ms (step) remaining time: 0:06:40
Validating ...
iter 7100: val loss 5.5905, val time: 4302.62 ms
Epoch 5 | iter 7110 step 7110 | loss train: 4.693, val: 5.591 | iter time: 141.72 ms (step) remaining time: 0:06:39
Epoch 5 | iter 7120 step 7120 | loss train: 4.748, val: 5.591 | iter time: 141.15 ms (step) remaining time: 0:06:37
Epoch 5 | iter 7130 step 7130 | loss train: 4.703, val: 5.591 | iter time: 142.21 ms (step) remaining time: 0:06:35
Epoch 5 | iter 7140 step 7140 | loss train: 4.677, val: 5.591 | iter time: 141.88 ms (step) remaining time: 0:06:33
Epoch 5 | iter 7150 step 7150 | loss train: 4.718, val: 5.591 | iter time: 142.02 ms (step) remaining time: 0:06:31
Epoch 5 | iter 7160 step 7160 | loss train: 4.672, val: 5.591 | iter time: 142.23 ms (step) remaining time: 0:06:29
Epoch 5 | iter 7170 step 7170 | loss train: 4.671, val: 5.591 | iter time: 142.15 ms (step) remaining time: 0:06:27
Epoch 5 | iter 7180 step 7180 | loss train: 4.719, val: 5.591 | iter time: 141.40 ms (step) remaining time: 0:06:25
Epoch 5 | iter 7190 step 7190 | loss train: 4.708, val: 5.591 | iter time: 142.20 ms (step) remaining time: 0:06:23
Epoch 5 | iter 7200 step 7200 | loss train: 4.702, val: 5.591 | iter time: 141.42 ms (step) remaining time: 0:06:20
Validating ...
iter 7200: val loss 5.5925, val time: 4297.53 ms
Epoch 5 | iter 7210 step 7210 | loss train: 4.693, val: 5.593 | iter time: 141.36 ms (step) remaining time: 0:06:20
Epoch 5 | iter 7220 step 7220 | loss train: 4.663, val: 5.593 | iter time: 143.06 ms (step) remaining time: 0:06:17
Epoch 5 | iter 7230 step 7230 | loss train: 4.698, val: 5.593 | iter time: 142.09 ms (step) remaining time: 0:06:15
Epoch 5 | iter 7240 step 7240 | loss train: 4.684, val: 5.593 | iter time: 142.50 ms (step) remaining time: 0:06:13
Epoch 5 | iter 7250 step 7250 | loss train: 4.673, val: 5.593 | iter time: 141.78 ms (step) remaining time: 0:06:11
Epoch 5 | iter 7260 step 7260 | loss train: 4.715, val: 5.593 | iter time: 142.07 ms (step) remaining time: 0:06:09
Epoch 5 | iter 7270 step 7270 | loss train: 4.693, val: 5.593 | iter time: 142.58 ms (step) remaining time: 0:06:07
Epoch 5 | iter 7280 step 7280 | loss train: 4.696, val: 5.593 | iter time: 142.41 ms (step) remaining time: 0:06:05
Epoch 5 | iter 7290 step 7290 | loss train: 4.637, val: 5.593 | iter time: 141.70 ms (step) remaining time: 0:06:03
Epoch 5 | iter 7300 step 7300 | loss train: 4.683, val: 5.593 | iter time: 142.19 ms (step) remaining time: 0:06:01
Validating ...
iter 7300: val loss 5.5925, val time: 4311.94 ms
Epoch 5 | iter 7310 step 7310 | loss train: 4.698, val: 5.592 | iter time: 141.70 ms (step) remaining time: 0:06:00
Epoch 5 | iter 7320 step 7320 | loss train: 4.704, val: 5.592 | iter time: 141.65 ms (step) remaining time: 0:05:58
Epoch 5 | iter 7330 step 7330 | loss train: 4.695, val: 5.592 | iter time: 142.87 ms (step) remaining time: 0:05:56
Epoch 5 | iter 7340 step 7340 | loss train: 4.702, val: 5.592 | iter time: 141.07 ms (step) remaining time: 0:05:53
Epoch 5 | iter 7350 step 7350 | loss train: 4.665, val: 5.592 | iter time: 141.83 ms (step) remaining time: 0:05:51
Epoch 5 | iter 7360 step 7360 | loss train: 4.738, val: 5.592 | iter time: 142.49 ms (step) remaining time: 0:05:49
Epoch 5 | iter 7370 step 7370 | loss train: 4.703, val: 5.592 | iter time: 141.70 ms (step) remaining time: 0:05:47
Epoch 5 | iter 7380 step 7380 | loss train: 4.717, val: 5.592 | iter time: 141.69 ms (step) remaining time: 0:05:45
Epoch 5 | iter 7390 step 7390 | loss train: 4.733, val: 5.592 | iter time: 142.31 ms (step) remaining time: 0:05:43
Epoch 5 | iter 7400 step 7400 | loss train: 4.664, val: 5.592 | iter time: 141.48 ms (step) remaining time: 0:05:41
Validating ...
iter 7400: val loss 5.5917, val time: 4319.89 ms
Epoch 5 | iter 7410 step 7410 | loss train: 4.747, val: 5.592 | iter time: 142.53 ms (step) remaining time: 0:05:40
Epoch 5 | iter 7420 step 7420 | loss train: 4.727, val: 5.592 | iter time: 142.09 ms (step) remaining time: 0:05:38
Epoch 5 | iter 7430 step 7430 | loss train: 4.715, val: 5.592 | iter time: 142.13 ms (step) remaining time: 0:05:36
Epoch 5 | iter 7440 step 7440 | loss train: 4.703, val: 5.592 | iter time: 142.27 ms (step) remaining time: 0:05:34
Epoch 5 | iter 7450 step 7450 | loss train: 4.675, val: 5.592 | iter time: 143.37 ms (step) remaining time: 0:05:32
Epoch 5 | iter 7460 step 7460 | loss train: 4.705, val: 5.592 | iter time: 142.91 ms (step) remaining time: 0:05:30
Epoch 5 | iter 7470 step 7470 | loss train: 4.693, val: 5.592 | iter time: 140.60 ms (step) remaining time: 0:05:27
Epoch 5 | iter 7480 step 7480 | loss train: 4.708, val: 5.592 | iter time: 142.88 ms (step) remaining time: 0:05:25
Epoch 5 | iter 7490 step 7490 | loss train: 4.733, val: 5.592 | iter time: 141.46 ms (step) remaining time: 0:05:23
Epoch 5 | iter 7500 step 7500 | loss train: 4.723, val: 5.592 | iter time: 142.97 ms (step) remaining time: 0:05:21
Validating ...
iter 7500: val loss 5.5914, val time: 4341.77 ms
Epoch 5 | iter 7510 step 7510 | loss train: 4.710, val: 5.591 | iter time: 141.66 ms (step) remaining time: 0:05:20
Epoch 5 | iter 7520 step 7520 | loss train: 4.697, val: 5.591 | iter time: 141.40 ms (step) remaining time: 0:05:18
Epoch 5 | iter 7530 step 7530 | loss train: 4.715, val: 5.591 | iter time: 142.54 ms (step) remaining time: 0:05:16
Epoch 5 | iter 7540 step 7540 | loss train: 4.713, val: 5.591 | iter time: 142.29 ms (step) remaining time: 0:05:14
Epoch 5 | iter 7550 step 7550 | loss train: 4.691, val: 5.591 | iter time: 143.37 ms (step) remaining time: 0:05:12
Epoch 5 | iter 7560 step 7560 | loss train: 4.706, val: 5.591 | iter time: 142.52 ms (step) remaining time: 0:05:10
Epoch 5 | iter 7570 step 7570 | loss train: 4.680, val: 5.591 | iter time: 144.10 ms (step) remaining time: 0:05:08
Epoch 5 | iter 7580 step 7580 | loss train: 4.663, val: 5.591 | iter time: 142.68 ms (step) remaining time: 0:05:06
Epoch 5 | iter 7590 step 7590 | loss train: 4.689, val: 5.591 | iter time: 142.05 ms (step) remaining time: 0:05:04
Epoch 5 | iter 7600 step 7600 | loss train: 4.686, val: 5.591 | iter time: 142.33 ms (step) remaining time: 0:05:02
Validating ...
iter 7600: val loss 5.5907, val time: 4324.64 ms
Epoch 5 | iter 7610 step 7610 | loss train: 4.703, val: 5.591 | iter time: 143.59 ms (step) remaining time: 0:05:00
Epoch 5 | iter 7620 step 7620 | loss train: 4.669, val: 5.591 | iter time: 143.06 ms (step) remaining time: 0:04:58
Epoch 5 | iter 7630 step 7630 | loss train: 4.661, val: 5.591 | iter time: 141.64 ms (step) remaining time: 0:04:56
Epoch 5 | iter 7640 step 7640 | loss train: 4.722, val: 5.591 | iter time: 141.80 ms (step) remaining time: 0:04:54
Epoch 5 | iter 7650 step 7650 | loss train: 4.697, val: 5.591 | iter time: 141.96 ms (step) remaining time: 0:04:52
Epoch 5 | iter 7660 step 7660 | loss train: 4.707, val: 5.591 | iter time: 142.76 ms (step) remaining time: 0:04:50
Epoch 5 | iter 7670 step 7670 | loss train: 4.665, val: 5.591 | iter time: 142.01 ms (step) remaining time: 0:04:48
Epoch 5 | iter 7680 step 7680 | loss train: 4.680, val: 5.591 | iter time: 142.64 ms (step) remaining time: 0:04:46
Epoch 5 | iter 7690 step 7690 | loss train: 4.679, val: 5.591 | iter time: 142.15 ms (step) remaining time: 0:04:44
Epoch 5 | iter 7700 step 7700 | loss train: 4.748, val: 5.591 | iter time: 142.74 ms (step) remaining time: 0:04:42
Validating ...
iter 7700: val loss 5.5879, val time: 4321.17 ms
Epoch 5 | iter 7710 step 7710 | loss train: 4.718, val: 5.588 | iter time: 143.36 ms (step) remaining time: 0:04:41
Epoch 5 | iter 7720 step 7720 | loss train: 4.707, val: 5.588 | iter time: 142.09 ms (step) remaining time: 0:04:39
Epoch 5 | iter 7730 step 7730 | loss train: 4.728, val: 5.588 | iter time: 143.89 ms (step) remaining time: 0:04:37
Epoch 5 | iter 7740 step 7740 | loss train: 4.678, val: 5.588 | iter time: 142.10 ms (step) remaining time: 0:04:35
Epoch 5 | iter 7750 step 7750 | loss train: 4.717, val: 5.588 | iter time: 142.11 ms (step) remaining time: 0:04:33
Epoch 5 | iter 7760 step 7760 | loss train: 4.683, val: 5.588 | iter time: 143.28 ms (step) remaining time: 0:04:31
Epoch 5 | iter 7770 step 7770 | loss train: 4.737, val: 5.588 | iter time: 142.38 ms (step) remaining time: 0:04:29
Epoch 5 | iter 7780 step 7780 | loss train: 4.641, val: 5.588 | iter time: 142.34 ms (step) remaining time: 0:04:27
Epoch 5 | iter 7790 step 7790 | loss train: 4.710, val: 5.588 | iter time: 142.34 ms (step) remaining time: 0:04:24
Epoch 5 | iter 7800 step 7800 | loss train: 4.686, val: 5.588 | iter time: 141.66 ms (step) remaining time: 0:04:22
Validating ...
iter 7800: val loss 5.5905, val time: 4322.15 ms
Epoch 5 | iter 7810 step 7810 | loss train: 4.684, val: 5.591 | iter time: 141.44 ms (step) remaining time: 0:04:21
Epoch 5 | iter 7820 step 7820 | loss train: 4.709, val: 5.591 | iter time: 141.74 ms (step) remaining time: 0:04:19
Epoch 5 | iter 7830 step 7830 | loss train: 4.650, val: 5.591 | iter time: 141.71 ms (step) remaining time: 0:04:17
Epoch 5 | iter 7840 step 7840 | loss train: 4.683, val: 5.591 | iter time: 142.46 ms (step) remaining time: 0:04:15
Epoch 5 | iter 7850 step 7850 | loss train: 4.713, val: 5.591 | iter time: 142.62 ms (step) remaining time: 0:04:13
Epoch 5 | iter 7860 step 7860 | loss train: 4.712, val: 5.591 | iter time: 142.62 ms (step) remaining time: 0:04:11
Epoch 5 | iter 7870 step 7870 | loss train: 4.712, val: 5.591 | iter time: 142.11 ms (step) remaining time: 0:04:09
Epoch 5 | iter 7880 step 7880 | loss train: 4.691, val: 5.591 | iter time: 141.82 ms (step) remaining time: 0:04:07
Epoch 5 | iter 7890 step 7890 | loss train: 4.712, val: 5.591 | iter time: 141.68 ms (step) remaining time: 0:04:05
Epoch 5 | iter 7900 step 7900 | loss train: 4.711, val: 5.591 | iter time: 143.44 ms (step) remaining time: 0:04:03
Validating ...
iter 7900: val loss 5.5903, val time: 4510.50 ms
Epoch 5 | iter 7910 step 7910 | loss train: 4.660, val: 5.590 | iter time: 141.20 ms (step) remaining time: 0:04:02
Epoch 5 | iter 7920 step 7920 | loss train: 4.690, val: 5.590 | iter time: 142.72 ms (step) remaining time: 0:04:00
Epoch 5 | iter 7930 step 7930 | loss train: 4.700, val: 5.590 | iter time: 142.15 ms (step) remaining time: 0:03:58
Epoch 5 | iter 7940 step 7940 | loss train: 4.719, val: 5.590 | iter time: 143.75 ms (step) remaining time: 0:03:55
Epoch 5 | iter 7950 step 7950 | loss train: 4.705, val: 5.590 | iter time: 142.70 ms (step) remaining time: 0:03:53
Epoch 5 | iter 7960 step 7960 | loss train: 4.722, val: 5.590 | iter time: 141.61 ms (step) remaining time: 0:03:51
Epoch 5 | iter 7970 step 7970 | loss train: 4.745, val: 5.590 | iter time: 141.79 ms (step) remaining time: 0:03:49
Epoch 6 | iter 7980 step 7980 | loss train: 4.672, val: 5.590 | iter time: 142.07 ms (step) remaining time: 0:03:47
Epoch 6 | iter 7990 step 7990 | loss train: 4.684, val: 5.590 | iter time: 143.51 ms (step) remaining time: 0:03:45
Epoch 6 | iter 8000 step 8000 | loss train: 4.673, val: 5.590 | iter time: 142.28 ms (step) remaining time: 0:03:43
Validating ...
iter 8000: val loss 5.5922, val time: 4316.27 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00008000/lit_model.pth'
Epoch 6 | iter 8010 step 8010 | loss train: 4.671, val: 5.592 | iter time: 141.47 ms (step) remaining time: 0:03:43
Epoch 6 | iter 8020 step 8020 | loss train: 4.663, val: 5.592 | iter time: 141.64 ms (step) remaining time: 0:03:41
Epoch 6 | iter 8030 step 8030 | loss train: 4.653, val: 5.592 | iter time: 142.32 ms (step) remaining time: 0:03:39
Epoch 6 | iter 8040 step 8040 | loss train: 4.623, val: 5.592 | iter time: 141.15 ms (step) remaining time: 0:03:37
Epoch 6 | iter 8050 step 8050 | loss train: 4.661, val: 5.592 | iter time: 141.91 ms (step) remaining time: 0:03:35
Epoch 6 | iter 8060 step 8060 | loss train: 4.690, val: 5.592 | iter time: 141.19 ms (step) remaining time: 0:03:33
Epoch 6 | iter 8070 step 8070 | loss train: 4.636, val: 5.592 | iter time: 141.70 ms (step) remaining time: 0:03:31
Epoch 6 | iter 8080 step 8080 | loss train: 4.640, val: 5.592 | iter time: 142.11 ms (step) remaining time: 0:03:29
Epoch 6 | iter 8090 step 8090 | loss train: 4.654, val: 5.592 | iter time: 141.14 ms (step) remaining time: 0:03:27
Epoch 6 | iter 8100 step 8100 | loss train: 4.688, val: 5.592 | iter time: 141.69 ms (step) remaining time: 0:03:25
Validating ...
iter 8100: val loss 5.5976, val time: 4306.05 ms
Epoch 6 | iter 8110 step 8110 | loss train: 4.662, val: 5.598 | iter time: 141.80 ms (step) remaining time: 0:03:24
Epoch 6 | iter 8120 step 8120 | loss train: 4.661, val: 5.598 | iter time: 141.18 ms (step) remaining time: 0:03:22
Epoch 6 | iter 8130 step 8130 | loss train: 4.661, val: 5.598 | iter time: 141.13 ms (step) remaining time: 0:03:20
Epoch 6 | iter 8140 step 8140 | loss train: 4.685, val: 5.598 | iter time: 141.68 ms (step) remaining time: 0:03:18
Epoch 6 | iter 8150 step 8150 | loss train: 4.664, val: 5.598 | iter time: 141.07 ms (step) remaining time: 0:03:16
Epoch 6 | iter 8160 step 8160 | loss train: 4.714, val: 5.598 | iter time: 141.39 ms (step) remaining time: 0:03:14
Epoch 6 | iter 8170 step 8170 | loss train: 4.642, val: 5.598 | iter time: 140.94 ms (step) remaining time: 0:03:12
Epoch 6 | iter 8180 step 8180 | loss train: 4.651, val: 5.598 | iter time: 142.61 ms (step) remaining time: 0:03:10
Epoch 6 | iter 8190 step 8190 | loss train: 4.659, val: 5.598 | iter time: 141.79 ms (step) remaining time: 0:03:08
Epoch 6 | iter 8200 step 8200 | loss train: 4.644, val: 5.598 | iter time: 141.32 ms (step) remaining time: 0:03:06
Validating ...
iter 8200: val loss 5.6037, val time: 4291.74 ms
Epoch 6 | iter 8210 step 8210 | loss train: 4.680, val: 5.604 | iter time: 142.27 ms (step) remaining time: 0:03:04
Epoch 6 | iter 8220 step 8220 | loss train: 4.678, val: 5.604 | iter time: 140.85 ms (step) remaining time: 0:03:02
Epoch 6 | iter 8230 step 8230 | loss train: 4.702, val: 5.604 | iter time: 141.41 ms (step) remaining time: 0:03:00
Epoch 6 | iter 8240 step 8240 | loss train: 4.658, val: 5.604 | iter time: 141.88 ms (step) remaining time: 0:02:58
Epoch 6 | iter 8250 step 8250 | loss train: 4.678, val: 5.604 | iter time: 142.20 ms (step) remaining time: 0:02:56
Epoch 6 | iter 8260 step 8260 | loss train: 4.687, val: 5.604 | iter time: 142.72 ms (step) remaining time: 0:02:54
Epoch 6 | iter 8270 step 8270 | loss train: 4.615, val: 5.604 | iter time: 141.91 ms (step) remaining time: 0:02:52
Epoch 6 | iter 8280 step 8280 | loss train: 4.672, val: 5.604 | iter time: 143.23 ms (step) remaining time: 0:02:50
Epoch 6 | iter 8290 step 8290 | loss train: 4.661, val: 5.604 | iter time: 142.27 ms (step) remaining time: 0:02:48
Epoch 6 | iter 8300 step 8300 | loss train: 4.604, val: 5.604 | iter time: 141.18 ms (step) remaining time: 0:02:46
Validating ...
iter 8300: val loss 5.6060, val time: 4329.98 ms
Epoch 6 | iter 8310 step 8310 | loss train: 4.673, val: 5.606 | iter time: 141.63 ms (step) remaining time: 0:02:44
Epoch 6 | iter 8320 step 8320 | loss train: 4.642, val: 5.606 | iter time: 141.58 ms (step) remaining time: 0:02:42
Epoch 6 | iter 8330 step 8330 | loss train: 4.640, val: 5.606 | iter time: 142.27 ms (step) remaining time: 0:02:40
Epoch 6 | iter 8340 step 8340 | loss train: 4.637, val: 5.606 | iter time: 141.49 ms (step) remaining time: 0:02:38
Epoch 6 | iter 8350 step 8350 | loss train: 4.614, val: 5.606 | iter time: 143.30 ms (step) remaining time: 0:02:36
Epoch 6 | iter 8360 step 8360 | loss train: 4.670, val: 5.606 | iter time: 141.72 ms (step) remaining time: 0:02:34
Epoch 6 | iter 8370 step 8370 | loss train: 4.628, val: 5.606 | iter time: 142.18 ms (step) remaining time: 0:02:32
Epoch 6 | iter 8380 step 8380 | loss train: 4.654, val: 5.606 | iter time: 140.92 ms (step) remaining time: 0:02:30
Epoch 6 | iter 8390 step 8390 | loss train: 4.614, val: 5.606 | iter time: 141.97 ms (step) remaining time: 0:02:28
Epoch 6 | iter 8400 step 8400 | loss train: 4.633, val: 5.606 | iter time: 142.75 ms (step) remaining time: 0:02:26
Validating ...
iter 8400: val loss 5.6052, val time: 4309.80 ms
Epoch 6 | iter 8410 step 8410 | loss train: 4.704, val: 5.605 | iter time: 141.38 ms (step) remaining time: 0:02:25
Epoch 6 | iter 8420 step 8420 | loss train: 4.650, val: 5.605 | iter time: 141.40 ms (step) remaining time: 0:02:23
Epoch 6 | iter 8430 step 8430 | loss train: 4.655, val: 5.605 | iter time: 142.88 ms (step) remaining time: 0:02:21
Epoch 6 | iter 8440 step 8440 | loss train: 4.668, val: 5.605 | iter time: 141.47 ms (step) remaining time: 0:02:19
Epoch 6 | iter 8450 step 8450 | loss train: 4.645, val: 5.605 | iter time: 141.49 ms (step) remaining time: 0:02:17
Epoch 6 | iter 8460 step 8460 | loss train: 4.656, val: 5.605 | iter time: 141.10 ms (step) remaining time: 0:02:15
Epoch 6 | iter 8470 step 8470 | loss train: 4.665, val: 5.605 | iter time: 142.95 ms (step) remaining time: 0:02:13
Epoch 6 | iter 8480 step 8480 | loss train: 4.665, val: 5.605 | iter time: 141.43 ms (step) remaining time: 0:02:11
Epoch 6 | iter 8490 step 8490 | loss train: 4.677, val: 5.605 | iter time: 142.07 ms (step) remaining time: 0:02:09
Epoch 6 | iter 8500 step 8500 | loss train: 4.679, val: 5.605 | iter time: 141.74 ms (step) remaining time: 0:02:07
Validating ...
iter 8500: val loss 5.6070, val time: 4298.46 ms
Epoch 6 | iter 8510 step 8510 | loss train: 4.625, val: 5.607 | iter time: 142.76 ms (step) remaining time: 0:02:05
Epoch 6 | iter 8520 step 8520 | loss train: 4.674, val: 5.607 | iter time: 140.59 ms (step) remaining time: 0:02:03
Epoch 6 | iter 8530 step 8530 | loss train: 4.638, val: 5.607 | iter time: 141.99 ms (step) remaining time: 0:02:01
Epoch 6 | iter 8540 step 8540 | loss train: 4.668, val: 5.607 | iter time: 143.36 ms (step) remaining time: 0:01:59
Epoch 6 | iter 8550 step 8550 | loss train: 4.634, val: 5.607 | iter time: 142.05 ms (step) remaining time: 0:01:57
Epoch 6 | iter 8560 step 8560 | loss train: 4.663, val: 5.607 | iter time: 142.28 ms (step) remaining time: 0:01:55
Epoch 6 | iter 8570 step 8570 | loss train: 4.679, val: 5.607 | iter time: 143.40 ms (step) remaining time: 0:01:53
Epoch 6 | iter 8580 step 8580 | loss train: 4.612, val: 5.607 | iter time: 141.87 ms (step) remaining time: 0:01:51
Epoch 6 | iter 8590 step 8590 | loss train: 4.640, val: 5.607 | iter time: 142.11 ms (step) remaining time: 0:01:49
Epoch 6 | iter 8600 step 8600 | loss train: 4.646, val: 5.607 | iter time: 142.72 ms (step) remaining time: 0:01:47
Validating ...
iter 8600: val loss 5.6057, val time: 4303.93 ms
Epoch 6 | iter 8610 step 8610 | loss train: 4.659, val: 5.606 | iter time: 141.07 ms (step) remaining time: 0:01:46
Epoch 6 | iter 8620 step 8620 | loss train: 4.670, val: 5.606 | iter time: 142.53 ms (step) remaining time: 0:01:44
Epoch 6 | iter 8630 step 8630 | loss train: 4.698, val: 5.606 | iter time: 141.71 ms (step) remaining time: 0:01:42
Epoch 6 | iter 8640 step 8640 | loss train: 4.622, val: 5.606 | iter time: 142.28 ms (step) remaining time: 0:01:40
Epoch 6 | iter 8650 step 8650 | loss train: 4.660, val: 5.606 | iter time: 141.25 ms (step) remaining time: 0:01:38
Epoch 6 | iter 8660 step 8660 | loss train: 4.669, val: 5.606 | iter time: 142.46 ms (step) remaining time: 0:01:36
Epoch 6 | iter 8670 step 8670 | loss train: 4.585, val: 5.606 | iter time: 142.58 ms (step) remaining time: 0:01:34
Epoch 6 | iter 8680 step 8680 | loss train: 4.686, val: 5.606 | iter time: 142.29 ms (step) remaining time: 0:01:32
Epoch 6 | iter 8690 step 8690 | loss train: 4.663, val: 5.606 | iter time: 142.70 ms (step) remaining time: 0:01:30
Epoch 6 | iter 8700 step 8700 | loss train: 4.655, val: 5.606 | iter time: 141.75 ms (step) remaining time: 0:01:28
Validating ...
iter 8700: val loss 5.6067, val time: 4334.51 ms
Epoch 6 | iter 8710 step 8710 | loss train: 4.674, val: 5.607 | iter time: 142.93 ms (step) remaining time: 0:01:26
Epoch 6 | iter 8720 step 8720 | loss train: 4.660, val: 5.607 | iter time: 142.61 ms (step) remaining time: 0:01:24
Epoch 6 | iter 8730 step 8730 | loss train: 4.622, val: 5.607 | iter time: 141.66 ms (step) remaining time: 0:01:22
Epoch 6 | iter 8740 step 8740 | loss train: 4.683, val: 5.607 | iter time: 142.53 ms (step) remaining time: 0:01:20
Epoch 6 | iter 8750 step 8750 | loss train: 4.675, val: 5.607 | iter time: 142.11 ms (step) remaining time: 0:01:18
Epoch 6 | iter 8760 step 8760 | loss train: 4.665, val: 5.607 | iter time: 142.81 ms (step) remaining time: 0:01:16
Epoch 6 | iter 8770 step 8770 | loss train: 4.655, val: 5.607 | iter time: 141.63 ms (step) remaining time: 0:01:14
Epoch 6 | iter 8780 step 8780 | loss train: 4.659, val: 5.607 | iter time: 142.14 ms (step) remaining time: 0:01:12
Epoch 6 | iter 8790 step 8790 | loss train: 4.668, val: 5.607 | iter time: 142.90 ms (step) remaining time: 0:01:10
Epoch 6 | iter 8800 step 8800 | loss train: 4.631, val: 5.607 | iter time: 142.72 ms (step) remaining time: 0:01:08
Validating ...
iter 8800: val loss 5.6070, val time: 4338.75 ms
Epoch 6 | iter 8810 step 8810 | loss train: 4.633, val: 5.607 | iter time: 142.29 ms (step) remaining time: 0:01:07
Epoch 6 | iter 8820 step 8820 | loss train: 4.664, val: 5.607 | iter time: 142.29 ms (step) remaining time: 0:01:05
Epoch 6 | iter 8830 step 8830 | loss train: 4.656, val: 5.607 | iter time: 142.17 ms (step) remaining time: 0:01:03
Epoch 6 | iter 8840 step 8840 | loss train: 4.629, val: 5.607 | iter time: 142.33 ms (step) remaining time: 0:01:01
Epoch 6 | iter 8850 step 8850 | loss train: 4.655, val: 5.607 | iter time: 141.78 ms (step) remaining time: 0:00:59
Epoch 6 | iter 8860 step 8860 | loss train: 4.647, val: 5.607 | iter time: 142.47 ms (step) remaining time: 0:00:57
Epoch 6 | iter 8870 step 8870 | loss train: 4.619, val: 5.607 | iter time: 142.11 ms (step) remaining time: 0:00:55
Epoch 6 | iter 8880 step 8880 | loss train: 4.674, val: 5.607 | iter time: 142.59 ms (step) remaining time: 0:00:53
Epoch 6 | iter 8890 step 8890 | loss train: 4.677, val: 5.607 | iter time: 142.84 ms (step) remaining time: 0:00:51
Epoch 6 | iter 8900 step 8900 | loss train: 4.667, val: 5.607 | iter time: 141.90 ms (step) remaining time: 0:00:49
Validating ...
iter 8900: val loss 5.6080, val time: 4310.66 ms
Epoch 6 | iter 8910 step 8910 | loss train: 4.650, val: 5.608 | iter time: 142.52 ms (step) remaining time: 0:00:47
Epoch 6 | iter 8920 step 8920 | loss train: 4.683, val: 5.608 | iter time: 141.83 ms (step) remaining time: 0:00:45
Epoch 6 | iter 8930 step 8930 | loss train: 4.660, val: 5.608 | iter time: 141.93 ms (step) remaining time: 0:00:43
Epoch 6 | iter 8940 step 8940 | loss train: 4.653, val: 5.608 | iter time: 142.27 ms (step) remaining time: 0:00:41
Epoch 6 | iter 8950 step 8950 | loss train: 4.660, val: 5.608 | iter time: 142.01 ms (step) remaining time: 0:00:39
Epoch 6 | iter 8960 step 8960 | loss train: 4.697, val: 5.608 | iter time: 141.81 ms (step) remaining time: 0:00:37
Epoch 6 | iter 8970 step 8970 | loss train: 4.666, val: 5.608 | iter time: 142.01 ms (step) remaining time: 0:00:35
Epoch 6 | iter 8980 step 8980 | loss train: 4.667, val: 5.608 | iter time: 142.93 ms (step) remaining time: 0:00:33
Epoch 6 | iter 8990 step 8990 | loss train: 4.662, val: 5.608 | iter time: 142.96 ms (step) remaining time: 0:00:32
Epoch 6 | iter 9000 step 9000 | loss train: 4.664, val: 5.608 | iter time: 141.64 ms (step) remaining time: 0:00:30
Validating ...
iter 9000: val loss 5.6083, val time: 4310.82 ms
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/step-00009000/lit_model.pth'
Epoch 6 | iter 9010 step 9010 | loss train: 4.674, val: 5.608 | iter time: 142.51 ms (step) remaining time: 0:00:28
Epoch 6 | iter 9020 step 9020 | loss train: 4.685, val: 5.608 | iter time: 141.04 ms (step) remaining time: 0:00:26
Epoch 6 | iter 9030 step 9030 | loss train: 4.651, val: 5.608 | iter time: 143.12 ms (step) remaining time: 0:00:24
Epoch 6 | iter 9040 step 9040 | loss train: 4.614, val: 5.608 | iter time: 141.71 ms (step) remaining time: 0:00:22
Epoch 6 | iter 9050 step 9050 | loss train: 4.633, val: 5.608 | iter time: 140.91 ms (step) remaining time: 0:00:20
Epoch 6 | iter 9060 step 9060 | loss train: 4.674, val: 5.608 | iter time: 141.42 ms (step) remaining time: 0:00:18
Epoch 6 | iter 9070 step 9070 | loss train: 4.662, val: 5.608 | iter time: 141.45 ms (step) remaining time: 0:00:16
Epoch 6 | iter 9080 step 9080 | loss train: 4.657, val: 5.608 | iter time: 141.31 ms (step) remaining time: 0:00:14
Epoch 6 | iter 9090 step 9090 | loss train: 4.651, val: 5.608 | iter time: 140.91 ms (step) remaining time: 0:00:12
Epoch 6 | iter 9100 step 9100 | loss train: 4.659, val: 5.608 | iter time: 141.69 ms (step) remaining time: 0:00:10
Validating ...
iter 9100: val loss 5.6060, val time: 4303.33 ms
Epoch 6 | iter 9110 step 9110 | loss train: 4.691, val: 5.606 | iter time: 141.51 ms (step) remaining time: 0:00:08
Epoch 6 | iter 9120 step 9120 | loss train: 4.728, val: 5.606 | iter time: 142.08 ms (step) remaining time: 0:00:06
Epoch 6 | iter 9130 step 9130 | loss train: 4.651, val: 5.606 | iter time: 141.92 ms (step) remaining time: 0:00:04
Epoch 6 | iter 9140 step 9140 | loss train: 4.665, val: 5.606 | iter time: 141.49 ms (step) remaining time: 0:00:02
Epoch 6 | iter 9150 step 9150 | loss train: 4.644, val: 5.606 | iter time: 141.80 ms (step) remaining time: 0:00:00
Validating ...
Final evaluation | val loss: 5.608 | val ppl: 272.589
Saving checkpoint to 'out/pretrain/custom-lm_75_1M_on_pcfg_50/final/lit_model.pth'
Training time: 1812.66s
Memory used: 24.93 GB
wandb: - 0.028 MB of 0.142 MB uploadedwandb: 
wandb: Run history:
wandb:                batches ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb: device/batches_per_sec ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà
wandb:   device/flops_per_sec ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà
wandb:   device/items_per_sec ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà
wandb:             device/mfu ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà
wandb: device/samples_per_sec ‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñÑ‚ñà‚ñà‚ñÑ‚ñà
wandb:                  epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                   iter ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:              iter_time ‚ñÅ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñÖ‚ñà‚ñá‚ñá‚ñá‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÑ‚ñá‚ñÜ‚ñá‚ñÜ
wandb:          learning_rate ‚ñÅ‚ñÉ‚ñÖ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                lengths ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                   loss ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         remaining_time ‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                samples ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                   step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                   time ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 tokens ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:           total_tokens ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:    trainer/global_step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               val_loss ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                val_ppl ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                batches 9150
wandb: device/batches_per_sec 7.09678
wandb:   device/flops_per_sec 77633694582361.06
wandb:   device/items_per_sec 232547.34389
wandb:             device/mfu 0.24883
wandb: device/samples_per_sec 227.09702
wandb:                  epoch 5
wandb:                   iter 9150
wandb:              iter_time 0.1418
wandb:          learning_rate 4e-05
wandb:                lengths 299827200
wandb:                   loss 4.64411
wandb:         remaining_time 0.97512
wandb:                samples 292800
wandb:                   step 9150
wandb:                   time 1784.47118
wandb:                 tokens 299827200
wandb:           total_tokens 299827200
wandb:    trainer/global_step 9155
wandb:               val_loss 5.60796
wandb:                val_ppl 272.58882
wandb: 
wandb: üöÄ View run dutiful-microwave-130 at: https://wandb.ai/pcfg_pretrain/pretrain-/runs/g2hjz72t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/pcfg_pretrain/pretrain-
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240707_152449-g2hjz72t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
